{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":594,"status":"ok","timestamp":1713421810328,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"oCXE-moU0r3-","outputId":"44ec9410-b307-4772-81d7-f21096f5b990"},"outputs":[],"source":["#%load_ext autoreload\n","#%autoreload 2\n","#%pdb\n","#import logging\n","#logging.basicConfig()\n","#logging.getLogger().setLevel(logging.DEBUG)\n","#logging.getLogger().setLevel(logging.INFO)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"text/plain":["'c:\\\\Users\\\\anast\\\\Documents\\\\EDU\\\\Master Thesis\\\\Experiments\\\\tda_for_fairness'"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","os.chdir(\"../\")\n","os.getcwd()"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57967,"status":"ok","timestamp":1713439802725,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"q-TMB86C1ASO","outputId":"37302031-fdcb-4104-fe8d-f3db701a2dae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing c:\\users\\anast\\documents\\edu\\master thesis\\experiments\\tda_for_fairness\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Getting requirements to build wheel: started\n","  Getting requirements to build wheel: finished with status 'done'\n","  Preparing metadata (pyproject.toml): started\n","  Preparing metadata (pyproject.toml): finished with status 'done'\n","Requirement already satisfied: datasets<3.0.0,>=2.18.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from tda-for-fairness==0.1.0) (2.18.0)\n","Requirement already satisfied: dill<0.4.0,>=0.3.8 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from tda-for-fairness==0.1.0) (0.3.8)\n","Requirement already satisfied: faiss-cpu<2.0.0,>=1.8.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from tda-for-fairness==0.1.0) (1.8.0)\n","Requirement already satisfied: lightning<3.0.0,>=2.2.2 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from tda-for-fairness==0.1.0) (2.2.2)\n","Requirement already satisfied: matplotlib<4.0.0,>=3.8.4 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from tda-for-fairness==0.1.0) (3.8.4)\n","Requirement already satisfied: pandas<3.0.0,>=2.2.2 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from tda-for-fairness==0.1.0) (2.2.2)\n","Requirement already satisfied: scikit-learn<2.0.0,>=1.4.2 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from tda-for-fairness==0.1.0) (1.4.2)\n","Requirement already satisfied: torch<3.0.0,>=2.2.2 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from tda-for-fairness==0.1.0) (2.2.2)\n","Requirement already satisfied: torchvision<0.18.0,>=0.17.2 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from tda-for-fairness==0.1.0) (0.17.2)\n","Requirement already satisfied: transformers<5.0.0,>=4.40.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from tda-for-fairness==0.1.0) (4.40.0)\n","Requirement already satisfied: filelock in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (3.13.4)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (1.26.4)\n","Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (15.0.2)\n","Requirement already satisfied: pyarrow-hotfix in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (0.6)\n","Requirement already satisfied: requests>=2.19.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (4.66.2)\n","Requirement already satisfied: xxhash in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (3.4.1)\n","Requirement already satisfied: multiprocess in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (2024.2.0)\n","Requirement already satisfied: aiohttp in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (0.22.2)\n","Requirement already satisfied: packaging in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (6.0.1)\n","Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from lightning<3.0.0,>=2.2.2->tda-for-fairness==0.1.0) (0.11.2)\n","Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from lightning<3.0.0,>=2.2.2->tda-for-fairness==0.1.0) (1.3.2)\n","Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from lightning<3.0.0,>=2.2.2->tda-for-fairness==0.1.0) (4.11.0)\n","Requirement already satisfied: pytorch-lightning in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from lightning<3.0.0,>=2.2.2->tda-for-fairness==0.1.0) (2.2.2)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.4->tda-for-fairness==0.1.0) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.4->tda-for-fairness==0.1.0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.4->tda-for-fairness==0.1.0) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.4->tda-for-fairness==0.1.0) (1.4.5)\n","Requirement already satisfied: pillow>=8 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.4->tda-for-fairness==0.1.0) (10.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.4->tda-for-fairness==0.1.0) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from matplotlib<4.0.0,>=3.8.4->tda-for-fairness==0.1.0) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from pandas<3.0.0,>=2.2.2->tda-for-fairness==0.1.0) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from pandas<3.0.0,>=2.2.2->tda-for-fairness==0.1.0) (2024.1)\n","Requirement already satisfied: scipy>=1.6.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from scikit-learn<2.0.0,>=1.4.2->tda-for-fairness==0.1.0) (1.13.0)\n","Requirement already satisfied: joblib>=1.2.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from scikit-learn<2.0.0,>=1.4.2->tda-for-fairness==0.1.0) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from scikit-learn<2.0.0,>=1.4.2->tda-for-fairness==0.1.0) (3.4.0)\n","Requirement already satisfied: sympy in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from torch<3.0.0,>=2.2.2->tda-for-fairness==0.1.0) (1.12)\n","Requirement already satisfied: networkx in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from torch<3.0.0,>=2.2.2->tda-for-fairness==0.1.0) (3.3)\n","Requirement already satisfied: jinja2 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from torch<3.0.0,>=2.2.2->tda-for-fairness==0.1.0) (3.1.3)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from transformers<5.0.0,>=4.40.0->tda-for-fairness==0.1.0) (2024.4.16)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from transformers<5.0.0,>=4.40.0->tda-for-fairness==0.1.0) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from transformers<5.0.0,>=4.40.0->tda-for-fairness==0.1.0) (0.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (1.9.4)\n","Requirement already satisfied: setuptools in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from lightning-utilities<2.0,>=0.8.0->lightning<3.0.0,>=2.2.2->tda-for-fairness==0.1.0) (69.5.1)\n","Requirement already satisfied: six>=1.5 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.8.4->tda-for-fairness==0.1.0) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from requests>=2.19.0->datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from requests>=2.19.0->datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from requests>=2.19.0->datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from requests>=2.19.0->datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (2024.2.2)\n","Requirement already satisfied: colorama in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from tqdm>=4.62.1->datasets<3.0.0,>=2.18.0->tda-for-fairness==0.1.0) (0.4.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from jinja2->torch<3.0.0,>=2.2.2->tda-for-fairness==0.1.0) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\anast\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tda-for-fairness-5qunvezw-py3.12\\lib\\site-packages (from sympy->torch<3.0.0,>=2.2.2->tda-for-fairness==0.1.0) (1.3.0)\n","Building wheels for collected packages: tda-for-fairness\n","  Building wheel for tda-for-fairness (pyproject.toml): started\n","  Building wheel for tda-for-fairness (pyproject.toml): finished with status 'done'\n","  Created wheel for tda-for-fairness: filename=tda_for_fairness-0.1.0-py3-none-any.whl size=1260 sha256=5aeff3794882055d9b86bda59b5de23fb61fe54a43a65e3ae83972536118817d\n","  Stored in directory: C:\\Users\\anast\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-xnvi338g\\wheels\\bf\\8e\\3d\\47794c43e1ae3369cb1cf80beb177ef5d02d031793fc4723d5\n","Successfully built tda-for-fairness\n","Installing collected packages: tda-for-fairness\n","  Attempting uninstall: tda-for-fairness\n","    Found existing installation: tda-for-fairness 0.1.0\n","    Uninstalling tda-for-fairness-0.1.0:\n","      Successfully uninstalled tda-for-fairness-0.1.0\n","Successfully installed tda-for-fairness-0.1.0\n"]}],"source":["# now change into the infembed directory\n","#%cd infembed\n","import sys\n","sys.path.insert(0, 'C:/Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed')\n","\n","# install the package\n","! pip install ."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":27618,"status":"ok","timestamp":1713439961487,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"WtBmxmW20r4C"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\anast\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tda-for-fairness-5qunVEZW-py3.12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from torch.utils.data import Subset, DataLoader, default_collate, Dataset\n","import torch.nn as nn\n","from infembed.clusterer._core.sklearn_clusterer import SklearnClusterer\n","from infembed.clusterer._core.faiss_clusterer import FAISSClusterer\n","from infembed.clusterer._core.rule_clusterer import RuleClusterer\n","from sklearn.cluster import KMeans\n","from tqdm import tqdm\n","import pandas as pd\n","import torch\n","from infembed.utils.common import Data\n","import matplotlib.pyplot as plt\n","from dataclasses import dataclass\n","import torch.nn.functional as F\n","import numpy as np\n","from transformers import DataCollatorWithPadding"]},{"cell_type":"markdown","metadata":{"id":"lcXeWnm40r4D"},"source":["#### figure out device to compute embeddings on ###"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1713439961488,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"1pPx89vG0r4F","outputId":"f0e594bb-9a41-4b29-d060-e42b5f71a5fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["device: cpu\n"]}],"source":["DEVICE = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n","print('device:', DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"oZv3dfKc0r4G"},"source":["#### load model"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333,"referenced_widgets":["089fbfa0c55d47e3ba7d8e5b16753176","3dbcdfd4ef894935a1bbb92e3574e777","1f36b20660234d00ae03463d663c601a","4041ebd2d65a4168819b41834cec6964","443e1b7211414a6da74753968bb7e82a","b5b688e1f10c4eb29baac238ee215411","46b3a835bd5a4f469d6a6411d8c915ba","9d9f2324a1aa4f4ebe21e5b108206c70","23b09e46890e421196833addbcc2974c","fcdd806adcaf477ba2138863a4628781","b20ac25335b94138a5b0b72b7a38e4f2","3a4588e26add47abb8dce591e05dc3c6","cf9b4c4adf2746b181a19414202cff05","11db5672df0c4110904a5af30949633b","559d33f3ffcf4192af9952a2c333277c","ae41758bbf6b430eb5ecab1b96ea0ff8","989876d8befc47a3b876ab8d51474024","aa74c8de1ae0467fa41670138eb37b7e","29e30877f88a4edf91cd30ab94416d50","41fa277be78f4c6b8d0ccb1d60e5426e","a1ed0b4d7e9149dfb0b863358f01ee6a","0f896251d121484ba71a8e53fcd12300","bb4c12b63127423ba5bb8ef3deb43aed","665c944864c24810ac5213d7a2975c1b","ed16d8969502476f9b854c8bdac69757","66c5d9e8a9794e258c82d427c518ae3e","74b4ac85e4e049b8b3effb9508c02801","edabf30aebf746e8b6cfff20b211ae05","1fa0fffe4e034eb5bd95a07f156ee253","e0c9d203273b46509dc18c1178af3969","dc6b31db6f514f18a3b785c268cb8fbf","7f12b6059f9643c7afeb913cedf4cd11","786284c1ccbf4dc3b9f4d92292360217","d900c5a3747d4f1693822a680e150305","e3ec58ad43f24cc88a628a79a2ec0700","48c0a6e7af6444109de88fb82e846512","4dc94c0a8e364e78a6855f5fd65495fd","4c5d37de37b14cdfb12423f128f0798d","2f8d3cbf852c44249e537c915c7007d4","6f21c77df7d1413d9abd3bf1aa3131cd","366fe9502717401e9c07fea7fbea13a1","7e7eef311a744414bdd17905c080ea3f","b61aab8be2194d50b00f1724cb65b30f","793f698c279447b7a9036a70b1d7c3a1","8c7f421795df4b469277a74bc4a4fcec","f355b48d81c244aa93d6b75bfd65e210","72ab1cc6356d4c70a4965c46ce104d95","3a48b97187a74d859df4e03e5fe06f0b","0c5c9baa63324176b41df1a183a4c92f","b449fb965413441c9a933cd3692c3680","662fecb18fe1402d810e05f4aec796ff","79e9b444543a47a9a211eb963cc89049","be399f9ab8434291a029ba2ef7f9ecab","808c87432b6446f7814389c7090bc71f","8b054d47d5ea498d856914509c8a405b","a93de48eb10b4e7abe651dad0633d526","dc8aef60efbf4d4aa38557987239c754","2f2e0567a0fd44f3944f21ffad84438c","fad42df95e0845f2bfdb0f938ca61774","d47e01c6bc204995b1745a1af187a91d","9b33e12dfc47467cb0d77aa7c6f93d2e","6887b63140644b5a998f689ff38cb151","9db9e04191fa46c586e6939a063b08d9","851905f19b6a4ae28e9e66c10e79af60","56780cf4e94942a38562f4ead034bd6e","0c112badf1474188aa33ef43e7dee7e8"]},"executionInfo":{"elapsed":10362,"status":"ok","timestamp":1713439971816,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"ZsUYaYpx0r4G","outputId":"08e5ab4d-4cb7-4b08-cb13-de5120eb7ffc"},"outputs":[],"source":["from transformers import AutoTokenizer, BertForSequenceClassification\n","tokenizer = AutoTokenizer.from_pretrained('fabriceyhc/bert-base-uncased-ag_news')\n","_model = BertForSequenceClassification.from_pretrained('fabriceyhc/bert-base-uncased-ag_news')"]},{"cell_type":"markdown","metadata":{"id":"gy5OAy2H0r4H"},"source":["#### wrap the model"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1713439971817,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"bJocsZhq0r4J","outputId":"7ed1294f-a295-4b85-dbc9-db6f22923c69"},"outputs":[{"data":{"text/plain":["WrappedModel(\n","  (model): BertForSequenceClassification(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0-11): 12 x BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Linear(in_features=768, out_features=4, bias=True)\n","  )\n",")"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["class WrappedModel(nn.Module):\n","    def __init__(self, model):\n","        super().__init__()\n","        self.model = model\n","\n","    def forward(self, batch):\n","        return self.model(**batch)\n","\n","model = WrappedModel(_model)\n","model.eval()\n","model.to(device=DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"hfRCxQ_O0r4K"},"source":["#### load dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["0e0298ff53c749ed97b6840f5b66b058","098d6f07eb1d405eacda4cf2878b69c1","1f35cb36518f40d8946d649c88481d9c","80276e6d08df4610922d0c8c70871c36","8675a42e1829469f83c3868f8babfaf9","29f9b3d23a5543d6ba063273a22ac4b3","ff1305043867418182a21b5459164622","c7c31c6cdf06449d9626dc05bb41ed08","b5f2c4cca4c64f7d957a2999918faabe","b3fb84ea2714478bbcb04ac7d8eeb54d","e63177bb4a7642278eb7a8674e0c959a","f6e58335649d4ae5b38de8dd9bad4da1","9602c555f9f7459391dde07172953630","ef5aeb5848a14807a59bb15589bfd253","162ae4630cfa464db7c337bceeb45ee0","e51b1f493cee48598f278f75e3b1791c","a8286f59810f4c248dac84c5b4c8294b","241d52645a454c618a5a11182a89d754","bcd6cc6e2d75462c87228178ad0ef329","2b853b166dc740a5be17c4cd7ff76c31","fc4d13aeaa844bb181b2127f82ab2b16","5910a7e2827540129ff32a6d25d963c0","9eff554f16bf44b0bb253d9453af6e9c","0cfba98e4e0244e7b516b773bd8f4e0b","4268b99847a9411fb008e400960b18ae","ce7cd3ff30a1408da253735dcf4e6dba","ceacfc34216e46a7bf8b93933e4c1c05","d2ba4a756ebe48d99a6bd7d7b12dcbb0","e8c956c5c373475e8961834bf6846f12","889dd502e5284867ba9ad4485e37287b","8384d218cb97468bacef63329ebde93f","bdb5a2b28c1842db8a8245bf5d958820","8feccdd3bc064cd38800c8edef512164","dd24e1a1fd424bd0b1e47a3598dcf5e1","1a18788ecde140eb9e3370064faf92e2","065f9297c0d6439297bd26066fb1c876","b9a424a5c7c8452096cd123e9530330d","0d469e2fcad743b581c4721449876c85","24b7063463cb4d15b102ca558b82f206","2c9ad1a526144820b99a573bb19b3efb","44cee22ed207492fb0d85cbcc3074c17","6b59e5cfbaf947eca750692fcf109b77","49aaf641478b48bfafcbeaa7dcee1a65","47c6d774fafc4022a35f6ecf071dbefb","7f26955c9fe544a89506f9ecb8cfbcc1","b779a1716f6a490ca4c3639ac3bacaf1","50ae707dce6645258a9f8b54e04df0fe","6d3a15340cf841d7bbd0a32ae3b369e0","de2c234c5f7b4928a4d2934e7cc74ebc","116e61e7c48f407db8e9b79bf69a279e","d612370820e34272ad46b4579d0b0aa8","6dfd626ab9c24852a27805be5c4613ba","9538c6b032b8415295a9f57b89cdfa06","b304365f3d6c4b5ca214b47544a581e4","6569a6359bde412987b2d664d1842c5c"]},"executionInfo":{"elapsed":6411,"status":"ok","timestamp":1713439978198,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"h363izJV0r4K","outputId":"fc4fe1d6-dd3d-407b-f637-ebebbdc8928b"},"outputs":[],"source":["from datasets import load_dataset\n","dataset = load_dataset(\"ag_news\")"]},{"cell_type":"markdown","metadata":{"id":"n_VKWyZl0r4L"},"source":["#### create the following:\n","- `eval_dataset`: `Dataset` for evaluation data where the raw text is a field, for use in displaying examples\n","- `eval_dataloader`: `DataLoader` constructed from `eval_dataset`.  This is given to the `EmbedderBase` implementation's `predict` method.\n","- `train_dataloader`: `DataLoader` for the training data.  This is given to the `EmbedderBase` implementation's `fit` method."]},{"cell_type":"markdown","metadata":{"id":"nU_E5w8-0r4L"},"source":["#### create `eval_dataset`"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1713439978885,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"IC6cHm620r4L","outputId":"484531b7-4c74-418d-a9cc-1fb375d7070f"},"outputs":[{"data":{"text/plain":["7600"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["eval_dataset = dataset['test']\n","len(eval_dataset)"]},{"cell_type":"markdown","metadata":{"id":"F04zmLAi0r4L"},"source":["#### create `eval_dataloader`"]},{"cell_type":"markdown","metadata":{"id":"llUWLBBq0r4L"},"source":["first, create a collate function that outputs a tuple, where both elements are what is output by huggingface's `DataCollatorWithPadding`.  This is because `EmbedderBase` implementations expect a batch to be a tuple, where the last element is the label"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448,"referenced_widgets":["95a90fe26d414859ac6335c5ec45273b","a7d0cbaec09847519068faa6bf69e7a1","eb3f8da3908b4d67bdf6e559eb03fc50","d8a091dff8ad48fc969a4202fe4c2e54","d5505849562145e1ba52653b53faa758","54847501dc6c4b0784a050b90a793ce6","2e6550884f404009811ba344440f5555","2ce4febc017c4d748703362b2c933f44","c47b3d8660874d0099d20cf9b4b394bf","bcc10b05097748d196204c8503835386","fede1881044744b0a7ff246cd78430b1"]},"executionInfo":{"elapsed":4616,"status":"ok","timestamp":1713439983491,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"_KYku5TT0r4M","outputId":"8df8dd3b-374e-4cf9-ca7c-276c724431c0"},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([[  101, 10069,  2005,  ...,     0,     0,     0],\n","         [  101,  1996,  2679,  ...,     0,     0,     0],\n","         [  101, 18712,  1012,  ...,     0,     0,     0],\n","         ...,\n","         [  101, 10478, 19439,  ...,     0,     0,     0],\n","         [  101,  2027,  1005,  ...,     0,     0,     0],\n","         [  101,  6505,  4057,  ...,     0,     0,     0]]),\n"," 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]]),\n"," 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         ...,\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0]]),\n"," 'labels': tensor([2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","         3, 3, 1, 1, 1, 1, 1, 1])}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["_collate_fn = DataCollatorWithPadding(tokenizer)\n","\n","def collate_fn(examples):\n","    _batch = _collate_fn(examples)\n","    _batch = {key:val.to(device=DEVICE) for (key, val) in _batch.items()}\n","    return (_batch, _batch[\"labels\"])\n","\n","eval_dataset_no_text = dataset[\"test\"]\n","eval_dataset_no_text = eval_dataset_no_text.map(\n","    lambda e: tokenizer(e[\"text\"]), batched=True\n",")\n","eval_dataset_no_text.set_format(\n","    type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"label\"]\n",")\n","eval_dataloader = torch.utils.data.DataLoader(\n","    eval_dataset_no_text, collate_fn=collate_fn, batch_size=32\n",")\n","batch, labels = next(iter(eval_dataloader))\n","batch"]},{"cell_type":"markdown","metadata":{"id":"BbSkKmuQ0r4M"},"source":["pass batch to model to test"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34681,"status":"ok","timestamp":1713440018144,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"IjCqG2QN0r4M","outputId":"780afbbd-c617-4773-d5a6-bdc1def5a5f0"},"outputs":[{"data":{"text/plain":["SequenceClassifierOutput(loss=tensor(0.1533, grad_fn=<NllLossBackward0>), logits=tensor([[ 1.8282, -3.8458,  2.7387, -2.4806],\n","        [-1.9454, -4.4805,  0.0072,  5.2491],\n","        [-1.4580, -4.4780, -0.5301,  5.1840],\n","        [-1.9375, -4.1853,  0.1949,  4.8149],\n","        [-0.0570, -4.0112, -1.5208,  4.3649],\n","        [-2.5590, -4.1836,  1.1783,  4.7290],\n","        [-2.1090, -4.5176,  0.2823,  5.2207],\n","        [-2.1285, -4.5300,  0.3136,  5.2297],\n","        [-1.3974, -4.2017,  0.2179,  4.3100],\n","        [-1.6491, -3.7142,  0.5749,  3.8798],\n","        [-2.5590, -4.2059,  1.1764,  4.7442],\n","        [-2.5594, -4.1536,  1.2848,  4.6271],\n","        [-2.5203, -4.1828,  1.2189,  4.6663],\n","        [ 0.0312, -4.1457, -1.6075,  4.4370],\n","        [-0.0116, -4.1598, -1.5903,  4.4650],\n","        [-0.0899, -3.8676, -1.4292,  4.2057],\n","        [-1.7844, -4.5857, -0.1131,  5.2909],\n","        [-1.4780, -4.2705, -0.5403,  5.0199],\n","        [-2.1323, -4.3248,  0.3273,  5.0337],\n","        [-2.3526, -4.1066,  1.1757,  4.4999],\n","        [-2.3688, -4.1862,  4.6390,  0.5447],\n","        [-1.8164, -4.4573,  0.0210,  5.0355],\n","        [-2.4348, -4.3051,  1.0223,  4.8222],\n","        [-2.3284, -4.1070,  1.4297,  4.2218],\n","        [-1.9248, -4.5821,  0.0341,  5.2927],\n","        [-1.9173, -4.5062,  0.0151,  5.2307],\n","        [-0.9195,  7.1310, -2.0105, -2.8099],\n","        [-1.0215,  6.4965, -1.7836, -2.2356],\n","        [-1.0276,  6.5628, -1.7907, -2.2937],\n","        [-1.0395,  7.0021, -1.9556, -2.5917],\n","        [-0.9170,  7.1603, -1.9856, -2.8475],\n","        [-0.9158,  7.1571, -1.9908, -2.8434]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["model(batch)"]},{"cell_type":"markdown","metadata":{"id":"ozHLOcyw0r4M"},"source":["#### create `train_dataloader`"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466,"referenced_widgets":["78151583c96e456081483aaa629690c3","71a3822a801446ec9a7551abbfb1c828","f0944b532a674b9b99773393d1be3584","5f624935fc234d10ade3b6b25c5ea9c9","72c0c5dc253d4f659a6047eeb2df8c1f","ec45db1861b141f186b9111135b4903b","7596deea0cbf4665b02dd1853e4ea068","4c5b8700fb604fd2a8dc333b21d0a554","718d0a315973410e9d351c72d7499aca","2aa13b24964d4dfcbced015c1ce66962","067d99e674664b43aeece0060bb7dbaf"]},"executionInfo":{"elapsed":1346,"status":"ok","timestamp":1713440019474,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"FYcUg6om0r4M","outputId":"5548cf15-f20f-42a4-e2a2-a2c45f35d884"},"outputs":[{"name":"stdout","output_type":"stream","text":["original training dataset length: 120000\n"]},{"name":"stderr","output_type":"stream","text":["Map: 100%|██████████| 5000/5000 [00:01<00:00, 2837.39 examples/s]\n"]},{"data":{"text/plain":["{'input_ids': tensor([[  101,  3748,  1051,  ...,  7659,  1012,   102],\n","         [  101,  5712,  1001,  ...,     0,     0,     0],\n","         [  101,  1999,  1996,  ...,     0,     0,     0],\n","         ...,\n","         [  101,  2710,  9326,  ...,     0,     0,     0],\n","         [  101,  2482,  5968,  ...,     0,     0,     0],\n","         [  101, 22098,  1001,  ...,     0,     0,     0]]),\n"," 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]]),\n"," 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         ...,\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0]]),\n"," 'labels': tensor([2, 0, 1, 2, 0, 1, 0, 0, 2, 2, 3, 3, 1, 0, 3, 0, 2, 3, 2, 0, 1, 2, 1, 0,\n","         2, 0, 2, 1, 3, 1, 0, 3])}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset_no_text = dataset[\"train\"]\n","train_dataset_no_text = train_dataset_no_text.shuffle()\n","print(\"original training dataset length:\", len(train_dataset_no_text))\n","NUM_TRAIN = 5000\n","train_dataset_no_text = train_dataset_no_text.select(list(range(NUM_TRAIN)))\n","train_dataset_no_text = train_dataset_no_text.map(\n","    lambda e: tokenizer(e[\"text\"]), batched=True\n",")\n","train_dataset_no_text.set_format(\n","    type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"label\"]\n",")\n","train_dataloader = torch.utils.data.DataLoader(\n","    train_dataset_no_text, collate_fn=collate_fn, batch_size=32\n",")\n","batch, _ = next(iter(train_dataloader))\n","batch"]},{"cell_type":"markdown","metadata":{"id":"0fbr0wGr0r4N"},"source":["#### define loss function"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1713440019474,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"b_oLF6000r4N"},"outputs":[],"source":["class HuggingFaceLoss(nn.Module):\n","    reduction: str = 'sum'\n","    def forward(self, out, batch):\n","        return F.cross_entropy(out['logits'], batch['labels'])\n","\n","loss_fn = HuggingFaceLoss()"]},{"cell_type":"markdown","metadata":{"id":"_TNSMF1m0r4N"},"source":["#### create embedder"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1713440019475,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"oObmonf20r4N","outputId":"2a50c3af-aad8-4e42-b7ca-6895601d981b"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\common.py:177: UserWarning: Setting required grads for layer: model.classifier., name: weight\n","  warnings.warn(\n","C:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\common.py:177: UserWarning: Setting required grads for layer: model.classifier., name: bias\n","  warnings.warn(\n","C:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\common.py:177: UserWarning: Setting required grads for layer: model.bert.encoder.layer.11.attention.self.query, name: weight\n","  warnings.warn(\n","C:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\common.py:177: UserWarning: Setting required grads for layer: model.bert.encoder.layer.11.attention.self.query, name: bias\n","  warnings.warn(\n","C:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\common.py:177: UserWarning: Setting required grads for layer: model.bert.encoder.layer.11.attention.self.key, name: weight\n","  warnings.warn(\n","C:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\common.py:177: UserWarning: Setting required grads for layer: model.bert.encoder.layer.11.attention.self.key, name: bias\n","  warnings.warn(\n","C:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\common.py:177: UserWarning: Setting required grads for layer: model.bert.encoder.layer.11.attention.self.value, name: weight\n","  warnings.warn(\n","C:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\common.py:177: UserWarning: Setting required grads for layer: model.bert.encoder.layer.11.attention.self.value, name: bias\n","  warnings.warn(\n","C:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\common.py:177: UserWarning: Setting required grads for layer: model.bert.encoder.layer.11.attention.output.dense, name: weight\n","  warnings.warn(\n","C:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\common.py:177: UserWarning: Setting required grads for layer: model.bert.encoder.layer.11.attention.output.dense, name: bias\n","  warnings.warn(\n","C:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\common.py:177: UserWarning: Setting required grads for layer: model.bert.encoder.layer.11.intermediate.dense, name: weight\n","  warnings.warn(\n","C:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\common.py:177: UserWarning: Setting required grads for layer: model.bert.encoder.layer.11.intermediate.dense, name: bias\n","  warnings.warn(\n","C:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\common.py:177: UserWarning: Setting required grads for layer: model.bert.encoder.layer.11.output.dense, name: weight\n","  warnings.warn(\n","C:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\common.py:177: UserWarning: Setting required grads for layer: model.bert.encoder.layer.11.output.dense, name: bias\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["consider gradients in the following layers: [Linear(in_features=768, out_features=4, bias=True), Linear(in_features=768, out_features=768, bias=True), Linear(in_features=768, out_features=768, bias=True), Linear(in_features=768, out_features=768, bias=True), Linear(in_features=768, out_features=768, bias=True), Linear(in_features=768, out_features=3072, bias=True), Linear(in_features=3072, out_features=768, bias=True)]\n"]}],"source":["from infembed.embedder._core.arnoldi_embedder import ArnoldiEmbedder\n","embedder = ArnoldiEmbedder(\n","    model=model,\n","    layers=[\n","        \"model.classifier\",\n","        \"model.bert.encoder.layer.11\",\n","    ],\n","    loss_fn=loss_fn,\n","    sample_wise_grads_per_batch=True,\n","    arnoldi_dim=200,\n","    projection_dim=50,\n","    show_progress=True,\n",")"]},{"cell_type":"markdown","metadata":{"id":"uJBqppz70r4N"},"source":["#### fit"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10311046,"status":"ok","timestamp":1713432339763,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"Osivf_JZ0r4N","outputId":"e935c2f3-3aa5-4660-b97a-3b23a23c1e04"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:root:start arnoldi iteration\n","INFO:root:start `_parameter_arnoldi`\n","Running Arnoldi Iteration for step:   0%|          | 0/200 [00:00<?, ?it/s]INFO:root:arnoldi iteration step 1\n","Running Arnoldi Iteration for step:   0%|          | 1/200 [00:45<2:31:45, 45.75s/it]INFO:root:arnoldi iteration step 2\n","Running Arnoldi Iteration for step:   1%|          | 2/200 [01:34<2:37:21, 47.69s/it]INFO:root:arnoldi iteration step 3\n","Running Arnoldi Iteration for step:   2%|▏         | 3/200 [02:22<2:36:47, 47.75s/it]INFO:root:arnoldi iteration step 4\n","Running Arnoldi Iteration for step:   2%|▏         | 4/200 [03:11<2:36:48, 48.00s/it]INFO:root:arnoldi iteration step 5\n","Running Arnoldi Iteration for step:   2%|▎         | 5/200 [03:59<2:36:22, 48.11s/it]INFO:root:arnoldi iteration step 6\n","Running Arnoldi Iteration for step:   3%|▎         | 6/200 [04:47<2:35:49, 48.19s/it]INFO:root:arnoldi iteration step 7\n","Running Arnoldi Iteration for step:   4%|▎         | 7/200 [05:36<2:35:28, 48.33s/it]INFO:root:arnoldi iteration step 8\n","Running Arnoldi Iteration for step:   4%|▍         | 8/200 [06:24<2:34:49, 48.38s/it]INFO:root:arnoldi iteration step 9\n","Running Arnoldi Iteration for step:   4%|▍         | 9/200 [07:13<2:34:00, 48.38s/it]INFO:root:arnoldi iteration step 10\n","Running Arnoldi Iteration for step:   5%|▌         | 10/200 [08:01<2:33:14, 48.39s/it]INFO:root:arnoldi iteration step 11\n","Running Arnoldi Iteration for step:   6%|▌         | 11/200 [08:50<2:32:32, 48.43s/it]INFO:root:arnoldi iteration step 12\n","Running Arnoldi Iteration for step:   6%|▌         | 12/200 [09:38<2:31:56, 48.49s/it]INFO:root:arnoldi iteration step 13\n","Running Arnoldi Iteration for step:   6%|▋         | 13/200 [10:27<2:31:22, 48.57s/it]INFO:root:arnoldi iteration step 14\n","Running Arnoldi Iteration for step:   7%|▋         | 14/200 [11:16<2:30:39, 48.60s/it]INFO:root:arnoldi iteration step 15\n","Running Arnoldi Iteration for step:   8%|▊         | 15/200 [12:04<2:29:58, 48.64s/it]INFO:root:arnoldi iteration step 16\n","Running Arnoldi Iteration for step:   8%|▊         | 16/200 [12:53<2:29:14, 48.66s/it]INFO:root:arnoldi iteration step 17\n","Running Arnoldi Iteration for step:   8%|▊         | 17/200 [13:42<2:28:30, 48.69s/it]INFO:root:arnoldi iteration step 18\n","Running Arnoldi Iteration for step:   9%|▉         | 18/200 [14:31<2:27:45, 48.71s/it]INFO:root:arnoldi iteration step 19\n","Running Arnoldi Iteration for step:  10%|▉         | 19/200 [15:19<2:26:57, 48.72s/it]INFO:root:arnoldi iteration step 20\n","Running Arnoldi Iteration for step:  10%|█         | 20/200 [16:08<2:26:14, 48.75s/it]INFO:root:arnoldi iteration step 21\n","Running Arnoldi Iteration for step:  10%|█         | 21/200 [16:57<2:25:29, 48.77s/it]INFO:root:arnoldi iteration step 22\n","Running Arnoldi Iteration for step:  11%|█         | 22/200 [17:46<2:24:46, 48.80s/it]INFO:root:arnoldi iteration step 23\n","Running Arnoldi Iteration for step:  12%|█▏        | 23/200 [18:35<2:24:06, 48.85s/it]INFO:root:arnoldi iteration step 24\n","Running Arnoldi Iteration for step:  12%|█▏        | 24/200 [19:24<2:23:25, 48.89s/it]INFO:root:arnoldi iteration step 25\n","Running Arnoldi Iteration for step:  12%|█▎        | 25/200 [20:13<2:22:38, 48.90s/it]INFO:root:arnoldi iteration step 26\n","Running Arnoldi Iteration for step:  13%|█▎        | 26/200 [21:02<2:21:55, 48.94s/it]INFO:root:arnoldi iteration step 27\n","Running Arnoldi Iteration for step:  14%|█▎        | 27/200 [21:51<2:21:19, 49.02s/it]INFO:root:arnoldi iteration step 28\n","Running Arnoldi Iteration for step:  14%|█▍        | 28/200 [22:40<2:20:37, 49.06s/it]INFO:root:arnoldi iteration step 29\n","Running Arnoldi Iteration for step:  14%|█▍        | 29/200 [23:29<2:19:50, 49.07s/it]INFO:root:arnoldi iteration step 30\n","Running Arnoldi Iteration for step:  15%|█▌        | 30/200 [24:18<2:19:06, 49.10s/it]INFO:root:arnoldi iteration step 31\n","Running Arnoldi Iteration for step:  16%|█▌        | 31/200 [25:08<2:18:26, 49.15s/it]INFO:root:arnoldi iteration step 32\n","Running Arnoldi Iteration for step:  16%|█▌        | 32/200 [25:57<2:17:41, 49.18s/it]INFO:root:arnoldi iteration step 33\n","Running Arnoldi Iteration for step:  16%|█▋        | 33/200 [26:46<2:16:42, 49.12s/it]INFO:root:arnoldi iteration step 34\n","Running Arnoldi Iteration for step:  17%|█▋        | 34/200 [27:35<2:15:49, 49.10s/it]INFO:root:arnoldi iteration step 35\n","Running Arnoldi Iteration for step:  18%|█▊        | 35/200 [28:24<2:15:01, 49.10s/it]INFO:root:arnoldi iteration step 36\n","Running Arnoldi Iteration for step:  18%|█▊        | 36/200 [29:13<2:14:14, 49.11s/it]INFO:root:arnoldi iteration step 37\n","Running Arnoldi Iteration for step:  18%|█▊        | 37/200 [30:02<2:13:24, 49.11s/it]INFO:root:arnoldi iteration step 38\n","Running Arnoldi Iteration for step:  19%|█▉        | 38/200 [30:51<2:12:33, 49.09s/it]INFO:root:arnoldi iteration step 39\n","Running Arnoldi Iteration for step:  20%|█▉        | 39/200 [31:40<2:11:45, 49.10s/it]INFO:root:arnoldi iteration step 40\n","Running Arnoldi Iteration for step:  20%|██        | 40/200 [32:30<2:11:03, 49.15s/it]INFO:root:arnoldi iteration step 41\n","Running Arnoldi Iteration for step:  20%|██        | 41/200 [33:19<2:10:16, 49.16s/it]INFO:root:arnoldi iteration step 42\n","Running Arnoldi Iteration for step:  21%|██        | 42/200 [34:08<2:09:28, 49.17s/it]INFO:root:arnoldi iteration step 43\n","Running Arnoldi Iteration for step:  22%|██▏       | 43/200 [34:57<2:08:39, 49.17s/it]INFO:root:arnoldi iteration step 44\n","Running Arnoldi Iteration for step:  22%|██▏       | 44/200 [35:47<2:07:56, 49.21s/it]INFO:root:arnoldi iteration step 45\n","Running Arnoldi Iteration for step:  22%|██▎       | 45/200 [36:36<2:07:12, 49.24s/it]INFO:root:arnoldi iteration step 46\n","Running Arnoldi Iteration for step:  23%|██▎       | 46/200 [37:25<2:06:25, 49.26s/it]INFO:root:arnoldi iteration step 47\n","Running Arnoldi Iteration for step:  24%|██▎       | 47/200 [38:14<2:05:41, 49.29s/it]INFO:root:arnoldi iteration step 48\n","Running Arnoldi Iteration for step:  24%|██▍       | 48/200 [39:04<2:04:52, 49.29s/it]INFO:root:arnoldi iteration step 49\n","Running Arnoldi Iteration for step:  24%|██▍       | 49/200 [39:53<2:04:20, 49.41s/it]INFO:root:arnoldi iteration step 50\n","Running Arnoldi Iteration for step:  25%|██▌       | 50/200 [40:43<2:03:33, 49.42s/it]INFO:root:arnoldi iteration step 51\n","Running Arnoldi Iteration for step:  26%|██▌       | 51/200 [41:32<2:02:44, 49.42s/it]INFO:root:arnoldi iteration step 52\n","Running Arnoldi Iteration for step:  26%|██▌       | 52/200 [42:22<2:02:03, 49.48s/it]INFO:root:arnoldi iteration step 53\n","Running Arnoldi Iteration for step:  26%|██▋       | 53/200 [43:12<2:01:17, 49.50s/it]INFO:root:arnoldi iteration step 54\n","Running Arnoldi Iteration for step:  27%|██▋       | 54/200 [44:01<2:00:42, 49.61s/it]INFO:root:arnoldi iteration step 55\n","Running Arnoldi Iteration for step:  28%|██▊       | 55/200 [44:51<1:59:56, 49.63s/it]INFO:root:arnoldi iteration step 56\n","Running Arnoldi Iteration for step:  28%|██▊       | 56/200 [45:41<1:59:01, 49.59s/it]INFO:root:arnoldi iteration step 57\n","Running Arnoldi Iteration for step:  28%|██▊       | 57/200 [46:30<1:58:12, 49.60s/it]INFO:root:arnoldi iteration step 58\n","Running Arnoldi Iteration for step:  29%|██▉       | 58/200 [47:20<1:57:21, 49.59s/it]INFO:root:arnoldi iteration step 59\n","Running Arnoldi Iteration for step:  30%|██▉       | 59/200 [48:09<1:56:35, 49.62s/it]INFO:root:arnoldi iteration step 60\n","Running Arnoldi Iteration for step:  30%|███       | 60/200 [48:59<1:55:44, 49.60s/it]INFO:root:arnoldi iteration step 61\n","Running Arnoldi Iteration for step:  30%|███       | 61/200 [49:49<1:54:56, 49.61s/it]INFO:root:arnoldi iteration step 62\n","Running Arnoldi Iteration for step:  31%|███       | 62/200 [50:38<1:54:04, 49.60s/it]INFO:root:arnoldi iteration step 63\n","Running Arnoldi Iteration for step:  32%|███▏      | 63/200 [51:28<1:53:20, 49.64s/it]INFO:root:arnoldi iteration step 64\n","Running Arnoldi Iteration for step:  32%|███▏      | 64/200 [52:18<1:52:30, 49.64s/it]INFO:root:arnoldi iteration step 65\n","Running Arnoldi Iteration for step:  32%|███▎      | 65/200 [53:07<1:51:40, 49.64s/it]INFO:root:arnoldi iteration step 66\n","Running Arnoldi Iteration for step:  33%|███▎      | 66/200 [53:57<1:51:01, 49.71s/it]INFO:root:arnoldi iteration step 67\n","Running Arnoldi Iteration for step:  34%|███▎      | 67/200 [54:47<1:50:29, 49.84s/it]INFO:root:arnoldi iteration step 68\n","Running Arnoldi Iteration for step:  34%|███▍      | 68/200 [55:37<1:49:44, 49.88s/it]INFO:root:arnoldi iteration step 69\n","Running Arnoldi Iteration for step:  34%|███▍      | 69/200 [56:27<1:48:55, 49.89s/it]INFO:root:arnoldi iteration step 70\n","Running Arnoldi Iteration for step:  35%|███▌      | 70/200 [57:17<1:48:02, 49.86s/it]INFO:root:arnoldi iteration step 71\n","Running Arnoldi Iteration for step:  36%|███▌      | 71/200 [58:07<1:47:09, 49.84s/it]INFO:root:arnoldi iteration step 72\n","Running Arnoldi Iteration for step:  36%|███▌      | 72/200 [58:57<1:46:28, 49.91s/it]INFO:root:arnoldi iteration step 73\n","Running Arnoldi Iteration for step:  36%|███▋      | 73/200 [59:47<1:45:35, 49.88s/it]INFO:root:arnoldi iteration step 74\n","Running Arnoldi Iteration for step:  37%|███▋      | 74/200 [1:00:37<1:44:47, 49.90s/it]INFO:root:arnoldi iteration step 75\n","Running Arnoldi Iteration for step:  38%|███▊      | 75/200 [1:01:26<1:43:57, 49.90s/it]INFO:root:arnoldi iteration step 76\n","Running Arnoldi Iteration for step:  38%|███▊      | 76/200 [1:02:17<1:43:18, 49.99s/it]INFO:root:arnoldi iteration step 77\n","Running Arnoldi Iteration for step:  38%|███▊      | 77/200 [1:03:07<1:42:34, 50.04s/it]INFO:root:arnoldi iteration step 78\n","Running Arnoldi Iteration for step:  39%|███▉      | 78/200 [1:03:57<1:41:35, 49.96s/it]INFO:root:arnoldi iteration step 79\n","Running Arnoldi Iteration for step:  40%|███▉      | 79/200 [1:04:47<1:40:48, 49.99s/it]INFO:root:arnoldi iteration step 80\n","Running Arnoldi Iteration for step:  40%|████      | 80/200 [1:05:37<1:40:06, 50.06s/it]INFO:root:arnoldi iteration step 81\n","Running Arnoldi Iteration for step:  40%|████      | 81/200 [1:06:27<1:39:21, 50.10s/it]INFO:root:arnoldi iteration step 82\n","Running Arnoldi Iteration for step:  41%|████      | 82/200 [1:07:17<1:38:34, 50.12s/it]INFO:root:arnoldi iteration step 83\n","Running Arnoldi Iteration for step:  42%|████▏     | 83/200 [1:08:08<1:37:53, 50.20s/it]INFO:root:arnoldi iteration step 84\n","Running Arnoldi Iteration for step:  42%|████▏     | 84/200 [1:08:58<1:37:15, 50.30s/it]INFO:root:arnoldi iteration step 85\n","Running Arnoldi Iteration for step:  42%|████▎     | 85/200 [1:09:49<1:36:32, 50.37s/it]INFO:root:arnoldi iteration step 86\n","Running Arnoldi Iteration for step:  43%|████▎     | 86/200 [1:10:39<1:35:27, 50.24s/it]INFO:root:arnoldi iteration step 87\n","Running Arnoldi Iteration for step:  44%|████▎     | 87/200 [1:11:29<1:34:37, 50.24s/it]INFO:root:arnoldi iteration step 88\n","Running Arnoldi Iteration for step:  44%|████▍     | 88/200 [1:12:19<1:33:51, 50.28s/it]INFO:root:arnoldi iteration step 89\n","Running Arnoldi Iteration for step:  44%|████▍     | 89/200 [1:13:09<1:32:58, 50.26s/it]INFO:root:arnoldi iteration step 90\n","Running Arnoldi Iteration for step:  45%|████▌     | 90/200 [1:13:59<1:32:00, 50.19s/it]INFO:root:arnoldi iteration step 91\n","Running Arnoldi Iteration for step:  46%|████▌     | 91/200 [1:14:50<1:31:14, 50.22s/it]INFO:root:arnoldi iteration step 92\n","Running Arnoldi Iteration for step:  46%|████▌     | 92/200 [1:15:40<1:30:30, 50.28s/it]INFO:root:arnoldi iteration step 93\n","Running Arnoldi Iteration for step:  46%|████▋     | 93/200 [1:16:31<1:30:00, 50.47s/it]INFO:root:arnoldi iteration step 94\n","Running Arnoldi Iteration for step:  47%|████▋     | 94/200 [1:17:22<1:29:12, 50.49s/it]INFO:root:arnoldi iteration step 95\n","Running Arnoldi Iteration for step:  48%|████▊     | 95/200 [1:18:12<1:28:22, 50.50s/it]INFO:root:arnoldi iteration step 96\n","Running Arnoldi Iteration for step:  48%|████▊     | 96/200 [1:19:03<1:27:31, 50.49s/it]INFO:root:arnoldi iteration step 97\n","Running Arnoldi Iteration for step:  48%|████▊     | 97/200 [1:19:53<1:26:44, 50.52s/it]INFO:root:arnoldi iteration step 98\n","Running Arnoldi Iteration for step:  49%|████▉     | 98/200 [1:20:44<1:25:54, 50.54s/it]INFO:root:arnoldi iteration step 99\n","Running Arnoldi Iteration for step:  50%|████▉     | 99/200 [1:21:34<1:24:52, 50.42s/it]INFO:root:arnoldi iteration step 100\n","Running Arnoldi Iteration for step:  50%|█████     | 100/200 [1:22:25<1:24:14, 50.54s/it]INFO:root:arnoldi iteration step 101\n","Running Arnoldi Iteration for step:  50%|█████     | 101/200 [1:23:16<1:23:31, 50.62s/it]INFO:root:arnoldi iteration step 102\n","Running Arnoldi Iteration for step:  51%|█████     | 102/200 [1:24:06<1:22:41, 50.63s/it]INFO:root:arnoldi iteration step 103\n","Running Arnoldi Iteration for step:  52%|█████▏    | 103/200 [1:24:57<1:21:47, 50.59s/it]INFO:root:arnoldi iteration step 104\n","Running Arnoldi Iteration for step:  52%|█████▏    | 104/200 [1:25:47<1:20:55, 50.58s/it]INFO:root:arnoldi iteration step 105\n","Running Arnoldi Iteration for step:  52%|█████▎    | 105/200 [1:26:38<1:20:05, 50.59s/it]INFO:root:arnoldi iteration step 106\n","Running Arnoldi Iteration for step:  53%|█████▎    | 106/200 [1:27:29<1:19:23, 50.67s/it]INFO:root:arnoldi iteration step 107\n","Running Arnoldi Iteration for step:  54%|█████▎    | 107/200 [1:28:20<1:18:47, 50.83s/it]INFO:root:arnoldi iteration step 108\n","Running Arnoldi Iteration for step:  54%|█████▍    | 108/200 [1:29:11<1:17:55, 50.82s/it]INFO:root:arnoldi iteration step 109\n","Running Arnoldi Iteration for step:  55%|█████▍    | 109/200 [1:30:02<1:17:03, 50.81s/it]INFO:root:arnoldi iteration step 110\n","Running Arnoldi Iteration for step:  55%|█████▌    | 110/200 [1:30:53<1:16:21, 50.91s/it]INFO:root:arnoldi iteration step 111\n","Running Arnoldi Iteration for step:  56%|█████▌    | 111/200 [1:31:44<1:15:29, 50.89s/it]INFO:root:arnoldi iteration step 112\n","Running Arnoldi Iteration for step:  56%|█████▌    | 112/200 [1:32:35<1:14:46, 50.98s/it]INFO:root:arnoldi iteration step 113\n","Running Arnoldi Iteration for step:  56%|█████▋    | 113/200 [1:33:26<1:14:01, 51.06s/it]INFO:root:arnoldi iteration step 114\n","Running Arnoldi Iteration for step:  57%|█████▋    | 114/200 [1:34:17<1:13:07, 51.02s/it]INFO:root:arnoldi iteration step 115\n","Running Arnoldi Iteration for step:  57%|█████▊    | 115/200 [1:35:08<1:12:14, 51.00s/it]INFO:root:arnoldi iteration step 116\n","Running Arnoldi Iteration for step:  58%|█████▊    | 116/200 [1:35:59<1:11:23, 51.00s/it]INFO:root:arnoldi iteration step 117\n","Running Arnoldi Iteration for step:  58%|█████▊    | 117/200 [1:36:50<1:10:35, 51.03s/it]INFO:root:arnoldi iteration step 118\n","Running Arnoldi Iteration for step:  59%|█████▉    | 118/200 [1:37:41<1:09:46, 51.05s/it]INFO:root:arnoldi iteration step 119\n","Running Arnoldi Iteration for step:  60%|█████▉    | 119/200 [1:38:32<1:08:54, 51.04s/it]INFO:root:arnoldi iteration step 120\n","Running Arnoldi Iteration for step:  60%|██████    | 120/200 [1:39:23<1:07:57, 50.97s/it]INFO:root:arnoldi iteration step 121\n","Running Arnoldi Iteration for step:  60%|██████    | 121/200 [1:40:14<1:07:13, 51.06s/it]INFO:root:arnoldi iteration step 122\n","Running Arnoldi Iteration for step:  61%|██████    | 122/200 [1:41:05<1:06:26, 51.10s/it]INFO:root:arnoldi iteration step 123\n","Running Arnoldi Iteration for step:  62%|██████▏   | 123/200 [1:41:57<1:05:42, 51.20s/it]INFO:root:arnoldi iteration step 124\n","Running Arnoldi Iteration for step:  62%|██████▏   | 124/200 [1:42:48<1:04:50, 51.20s/it]INFO:root:arnoldi iteration step 125\n","Running Arnoldi Iteration for step:  62%|██████▎   | 125/200 [1:43:39<1:04:00, 51.20s/it]INFO:root:arnoldi iteration step 126\n","Running Arnoldi Iteration for step:  63%|██████▎   | 126/200 [1:44:30<1:03:03, 51.13s/it]INFO:root:arnoldi iteration step 127\n","Running Arnoldi Iteration for step:  64%|██████▎   | 127/200 [1:45:21<1:02:18, 51.21s/it]INFO:root:arnoldi iteration step 128\n","Running Arnoldi Iteration for step:  64%|██████▍   | 128/200 [1:46:13<1:01:29, 51.25s/it]INFO:root:arnoldi iteration step 129\n","Running Arnoldi Iteration for step:  64%|██████▍   | 129/200 [1:47:04<1:00:29, 51.11s/it]INFO:root:arnoldi iteration step 130\n","Running Arnoldi Iteration for step:  65%|██████▌   | 130/200 [1:47:55<59:39, 51.13s/it]  INFO:root:arnoldi iteration step 131\n","Running Arnoldi Iteration for step:  66%|██████▌   | 131/200 [1:48:46<58:54, 51.22s/it]INFO:root:arnoldi iteration step 132\n","Running Arnoldi Iteration for step:  66%|██████▌   | 132/200 [1:49:38<58:09, 51.31s/it]INFO:root:arnoldi iteration step 133\n","Running Arnoldi Iteration for step:  66%|██████▋   | 133/200 [1:50:29<57:21, 51.37s/it]INFO:root:arnoldi iteration step 134\n","Running Arnoldi Iteration for step:  67%|██████▋   | 134/200 [1:51:21<56:31, 51.39s/it]INFO:root:arnoldi iteration step 135\n","Running Arnoldi Iteration for step:  68%|██████▊   | 135/200 [1:52:12<55:39, 51.38s/it]INFO:root:arnoldi iteration step 136\n","Running Arnoldi Iteration for step:  68%|██████▊   | 136/200 [1:53:04<54:50, 51.41s/it]INFO:root:arnoldi iteration step 137\n","Running Arnoldi Iteration for step:  68%|██████▊   | 137/200 [1:53:55<54:04, 51.51s/it]INFO:root:arnoldi iteration step 138\n","Running Arnoldi Iteration for step:  69%|██████▉   | 138/200 [1:54:47<53:10, 51.47s/it]INFO:root:arnoldi iteration step 139\n","Running Arnoldi Iteration for step:  70%|██████▉   | 139/200 [1:55:38<52:17, 51.43s/it]INFO:root:arnoldi iteration step 140\n","Running Arnoldi Iteration for step:  70%|███████   | 140/200 [1:56:29<51:26, 51.45s/it]INFO:root:arnoldi iteration step 141\n","Running Arnoldi Iteration for step:  70%|███████   | 141/200 [1:57:21<50:36, 51.46s/it]INFO:root:arnoldi iteration step 142\n","Running Arnoldi Iteration for step:  71%|███████   | 142/200 [1:58:13<49:49, 51.54s/it]INFO:root:arnoldi iteration step 143\n","Running Arnoldi Iteration for step:  72%|███████▏  | 143/200 [1:59:04<48:53, 51.46s/it]INFO:root:arnoldi iteration step 144\n","Running Arnoldi Iteration for step:  72%|███████▏  | 144/200 [1:59:56<48:04, 51.50s/it]INFO:root:arnoldi iteration step 145\n","Running Arnoldi Iteration for step:  72%|███████▎  | 145/200 [2:00:47<47:19, 51.62s/it]INFO:root:arnoldi iteration step 146\n","Running Arnoldi Iteration for step:  73%|███████▎  | 146/200 [2:01:39<46:30, 51.68s/it]INFO:root:arnoldi iteration step 147\n","Running Arnoldi Iteration for step:  74%|███████▎  | 147/200 [2:02:31<45:40, 51.70s/it]INFO:root:arnoldi iteration step 148\n","Running Arnoldi Iteration for step:  74%|███████▍  | 148/200 [2:03:23<44:46, 51.66s/it]INFO:root:arnoldi iteration step 149\n","Running Arnoldi Iteration for step:  74%|███████▍  | 149/200 [2:04:15<43:58, 51.74s/it]INFO:root:arnoldi iteration step 150\n","Running Arnoldi Iteration for step:  75%|███████▌  | 150/200 [2:05:06<43:08, 51.77s/it]INFO:root:arnoldi iteration step 151\n","Running Arnoldi Iteration for step:  76%|███████▌  | 151/200 [2:05:58<42:16, 51.77s/it]INFO:root:arnoldi iteration step 152\n","Running Arnoldi Iteration for step:  76%|███████▌  | 152/200 [2:06:50<41:22, 51.71s/it]INFO:root:arnoldi iteration step 153\n","Running Arnoldi Iteration for step:  76%|███████▋  | 153/200 [2:07:42<40:34, 51.80s/it]INFO:root:arnoldi iteration step 154\n","Running Arnoldi Iteration for step:  77%|███████▋  | 154/200 [2:08:34<39:46, 51.88s/it]INFO:root:arnoldi iteration step 155\n","Running Arnoldi Iteration for step:  78%|███████▊  | 155/200 [2:09:26<38:54, 51.89s/it]INFO:root:arnoldi iteration step 156\n","Running Arnoldi Iteration for step:  78%|███████▊  | 156/200 [2:10:17<38:00, 51.83s/it]INFO:root:arnoldi iteration step 157\n","Running Arnoldi Iteration for step:  78%|███████▊  | 157/200 [2:11:10<37:16, 52.00s/it]INFO:root:arnoldi iteration step 158\n","Running Arnoldi Iteration for step:  79%|███████▉  | 158/200 [2:12:02<36:24, 52.00s/it]INFO:root:arnoldi iteration step 159\n","Running Arnoldi Iteration for step:  80%|███████▉  | 159/200 [2:12:54<35:30, 51.96s/it]INFO:root:arnoldi iteration step 160\n","Running Arnoldi Iteration for step:  80%|████████  | 160/200 [2:13:46<34:39, 51.98s/it]INFO:root:arnoldi iteration step 161\n","Running Arnoldi Iteration for step:  80%|████████  | 161/200 [2:14:38<33:50, 52.07s/it]INFO:root:arnoldi iteration step 162\n","Running Arnoldi Iteration for step:  81%|████████  | 162/200 [2:15:30<32:57, 52.04s/it]INFO:root:arnoldi iteration step 163\n","Running Arnoldi Iteration for step:  82%|████████▏ | 163/200 [2:16:22<32:07, 52.08s/it]INFO:root:arnoldi iteration step 164\n","Running Arnoldi Iteration for step:  82%|████████▏ | 164/200 [2:17:14<31:14, 52.06s/it]INFO:root:arnoldi iteration step 165\n","Running Arnoldi Iteration for step:  82%|████████▎ | 165/200 [2:18:07<30:27, 52.22s/it]INFO:root:arnoldi iteration step 166\n","Running Arnoldi Iteration for step:  83%|████████▎ | 166/200 [2:18:59<29:33, 52.16s/it]INFO:root:arnoldi iteration step 167\n","Running Arnoldi Iteration for step:  84%|████████▎ | 167/200 [2:19:51<28:37, 52.05s/it]INFO:root:arnoldi iteration step 168\n","Running Arnoldi Iteration for step:  84%|████████▍ | 168/200 [2:20:43<27:49, 52.16s/it]INFO:root:arnoldi iteration step 169\n","Running Arnoldi Iteration for step:  84%|████████▍ | 169/200 [2:21:35<26:59, 52.25s/it]INFO:root:arnoldi iteration step 170\n","Running Arnoldi Iteration for step:  85%|████████▌ | 170/200 [2:22:27<26:05, 52.18s/it]INFO:root:arnoldi iteration step 171\n","Running Arnoldi Iteration for step:  86%|████████▌ | 171/200 [2:23:19<25:11, 52.12s/it]INFO:root:arnoldi iteration step 172\n","Running Arnoldi Iteration for step:  86%|████████▌ | 172/200 [2:24:12<24:21, 52.20s/it]INFO:root:arnoldi iteration step 173\n","Running Arnoldi Iteration for step:  86%|████████▋ | 173/200 [2:25:04<23:28, 52.15s/it]INFO:root:arnoldi iteration step 174\n","Running Arnoldi Iteration for step:  87%|████████▋ | 174/200 [2:25:56<22:38, 52.24s/it]INFO:root:arnoldi iteration step 175\n","Running Arnoldi Iteration for step:  88%|████████▊ | 175/200 [2:26:49<21:47, 52.32s/it]INFO:root:arnoldi iteration step 176\n","Running Arnoldi Iteration for step:  88%|████████▊ | 176/200 [2:27:41<20:54, 52.27s/it]INFO:root:arnoldi iteration step 177\n","Running Arnoldi Iteration for step:  88%|████████▊ | 177/200 [2:28:33<20:03, 52.32s/it]INFO:root:arnoldi iteration step 178\n","Running Arnoldi Iteration for step:  89%|████████▉ | 178/200 [2:29:26<19:14, 52.46s/it]INFO:root:arnoldi iteration step 179\n","Running Arnoldi Iteration for step:  90%|████████▉ | 179/200 [2:30:19<18:21, 52.47s/it]INFO:root:arnoldi iteration step 180\n","Running Arnoldi Iteration for step:  90%|█████████ | 180/200 [2:31:11<17:29, 52.48s/it]INFO:root:arnoldi iteration step 181\n","Running Arnoldi Iteration for step:  90%|█████████ | 181/200 [2:32:04<16:40, 52.66s/it]INFO:root:arnoldi iteration step 182\n","Running Arnoldi Iteration for step:  91%|█████████ | 182/200 [2:32:57<15:47, 52.63s/it]INFO:root:arnoldi iteration step 183\n","Running Arnoldi Iteration for step:  92%|█████████▏| 183/200 [2:33:49<14:54, 52.62s/it]INFO:root:arnoldi iteration step 184\n","Running Arnoldi Iteration for step:  92%|█████████▏| 184/200 [2:34:42<14:03, 52.69s/it]INFO:root:arnoldi iteration step 185\n","Running Arnoldi Iteration for step:  92%|█████████▎| 185/200 [2:35:35<13:12, 52.81s/it]INFO:root:arnoldi iteration step 186\n","Running Arnoldi Iteration for step:  93%|█████████▎| 186/200 [2:36:28<12:18, 52.73s/it]INFO:root:arnoldi iteration step 187\n","Running Arnoldi Iteration for step:  94%|█████████▎| 187/200 [2:37:21<11:26, 52.78s/it]INFO:root:arnoldi iteration step 188\n","Running Arnoldi Iteration for step:  94%|█████████▍| 188/200 [2:38:13<10:32, 52.69s/it]INFO:root:arnoldi iteration step 189\n","Running Arnoldi Iteration for step:  94%|█████████▍| 189/200 [2:39:06<09:39, 52.72s/it]INFO:root:arnoldi iteration step 190\n","Running Arnoldi Iteration for step:  95%|█████████▌| 190/200 [2:39:59<08:48, 52.82s/it]INFO:root:arnoldi iteration step 191\n","Running Arnoldi Iteration for step:  96%|█████████▌| 191/200 [2:40:52<07:55, 52.80s/it]INFO:root:arnoldi iteration step 192\n","Running Arnoldi Iteration for step:  96%|█████████▌| 192/200 [2:41:44<07:01, 52.74s/it]INFO:root:arnoldi iteration step 193\n","Running Arnoldi Iteration for step:  96%|█████████▋| 193/200 [2:42:37<06:09, 52.82s/it]INFO:root:arnoldi iteration step 194\n","Running Arnoldi Iteration for step:  97%|█████████▋| 194/200 [2:43:30<05:16, 52.75s/it]INFO:root:arnoldi iteration step 195\n","Running Arnoldi Iteration for step:  98%|█████████▊| 195/200 [2:44:23<04:23, 52.72s/it]INFO:root:arnoldi iteration step 196\n","Running Arnoldi Iteration for step:  98%|█████████▊| 196/200 [2:45:16<03:30, 52.74s/it]INFO:root:arnoldi iteration step 197\n","Running Arnoldi Iteration for step:  98%|█████████▊| 197/200 [2:46:08<02:38, 52.74s/it]INFO:root:arnoldi iteration step 198\n","Running Arnoldi Iteration for step:  99%|█████████▉| 198/200 [2:47:01<01:45, 52.75s/it]INFO:root:arnoldi iteration step 199\n","Running Arnoldi Iteration for step: 100%|█████████▉| 199/200 [2:47:55<00:53, 53.06s/it]INFO:root:arnoldi iteration step 200\n","Running Arnoldi Iteration for step: 100%|██████████| 200/200 [2:48:48<00:00, 50.64s/it]\n","INFO:root:start `_parameter_distill`\n"]},{"data":{"text/plain":["<infembed.embedder._core.arnoldi_embedder.ArnoldiEmbedder at 0x7b31a8412f80>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["embedder.fit(train_dataloader)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":70224,"status":"ok","timestamp":1713433767910,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"c7_2wdfvkSGS"},"outputs":[],"source":["#with open(f'/content/drive/My Drive/embedder.pkl', 'wb') as f:\n","#    pickle.dump(embedder, f)\n","\n","# embedder.save(\"/content/drive/My Drive/embedder.pkl\")\n","# embedder.load(\"/content/drive/My Drive/embedder.pkl\", projection_on_cpu = True)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":37191,"status":"ok","timestamp":1713440064845,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"Xi3C8SaftcbO"},"outputs":[],"source":["import pickle\n","import io\n","\n","class CPU_Unpickler(pickle.Unpickler):\n","    def find_class(self, module, name):\n","        if module == 'torch.storage' and name == '_load_from_bytes':\n","            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n","        else:\n","            return super().find_class(module, name)\n","\n","with open(f'C:/Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/embedder.pkl', 'rb') as f:\n","     embedder = CPU_Unpickler(f).load()"]},{"cell_type":"markdown","metadata":{"id":"vmNggaum0r4N"},"source":["#### compute embeddings"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":944,"referenced_widgets":["5edf026c132644639f0c28037061f2a7","7b667b51c25e43dba344c409467e8f9d","5a1bca8446a149dc98a210584e8b951e","b5dc214cedf846e583b47fe751943d50","0c4aeac53f024b20bbc579ad6f36b0bf","488fb950b922473fb15816979b3cd33e","e82fa53de8f34cf79c1abf862452d503","f219e3fbc34f41bfbddfec77939cd957","0d2aa05e70a444488bde7c5146ea4be5","931f7157bdab4855b28e1a4ee5306f7f","e32393b2df724b2caf40e5acbe4e3683"]},"executionInfo":{"elapsed":687,"status":"error","timestamp":1713440858444,"user":{"displayName":"Kakit Law","userId":"06957130314624122701"},"user_tz":-120},"id":"irwmodSn0r4O","outputId":"b22eaf24-7fb5-4bcd-a337-cd62b0e889e7"},"outputs":[{"name":"stderr","output_type":"stream","text":["Using ArnoldiEmbedder to compute embeddings. Processing batch:   0%|          | 0/238 [00:00<?, ?it/s]\n"]},{"ename":"TypeError","evalue":"WrappedModel.forward() takes 2 positional arguments but 5 were given","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mC:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_core\\arnoldi_embedder.py:618\u001b[0m, in \u001b[0;36mArnoldiEmbedder.predict\u001b[1;34m(self, dataloader)\u001b[0m\n\u001b[0;32m    610\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    611\u001b[0m \u001b[38;5;66;03m########********ANA'S CODE*******###############\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;66;03m#embed_lst = []\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;66;03m#dataloader_iter = iter(dataloader)\u001b[39;00m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;66;03m#for _ in range(len(dataloader)):\u001b[39;00m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;66;03m#    embed_lst.append(get_batch_embeddings(next(dataloader_iter)))\u001b[39;00m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;66;03m########********ANA'S CODE*******###############\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m--> 618\u001b[0m     [\u001b[43mget_batch_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;66;03m#embed_lst, dim=0\u001b[39;00m\n\u001b[0;32m    620\u001b[0m )\n","File \u001b[1;32mC:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_core\\arnoldi_embedder.py:563\u001b[0m, in \u001b[0;36mArnoldiEmbedder.predict.<locals>.get_batch_embeddings\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    553\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(features)\n\u001b[0;32m    554\u001b[0m \u001b[38;5;66;03m#features = batch\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;66;03m#labels = batch[\"labels\"]\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;66;03m#print(batch)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;66;03m# `jacobians`` is a tensor of tuples. unlike parameters, however, the first\u001b[39;00m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# dimension is a batch dimension\u001b[39;00m\n\u001b[1;32m--> 563\u001b[0m jacobians \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_jacobian_sample_wise_grads_per_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_type\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;66;03m# `jacobians`` contains the per-example parameters for a batch. this\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;66;03m# function takes in `params`, a tuple of tensors representing a single\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;66;03m# parameter setting, and for each example, computes the dot-product of its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;66;03m# we can do the same computation without actually creating that list of\u001b[39;00m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;66;03m# tuple of tensors by using broadcasting.\u001b[39;00m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_batch_coordinate\u001b[39m(params):\n","File \u001b[1;32mC:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\common.py:352\u001b[0m, in \u001b[0;36m_compute_jacobian_sample_wise_grads_per_batch\u001b[1;34m(inst, inputs, targets, loss_fn, reduction_type)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_jacobian_sample_wise_grads_per_batch\u001b[39m(\n\u001b[0;32m    345\u001b[0m     inst: EmbedderBase,\n\u001b[0;32m    346\u001b[0m     inputs: Tuple[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], \u001b[38;5;66;03m# SHOULD BE Tuple[torch.Tensor,...]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m     reduction_type: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    350\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inst\u001b[38;5;241m.\u001b[39msample_wise_grads_per_batch:\n\u001b[1;32m--> 352\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compute_jacobian_wrt_params_with_sample_wise_trick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m            \u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduction_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m            \u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compute_jacobian_wrt_params(\n\u001b[0;32m    361\u001b[0m         inst\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    362\u001b[0m         inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m         inst\u001b[38;5;241m.\u001b[39mlayer_modules,\n\u001b[0;32m    366\u001b[0m     )\n","File \u001b[1;32mC:\\Users/anast/Documents/EDU/Master Thesis/Experiments/exp/infembed_exp/infembed\\infembed\\embedder\\_utils\\gradient.py:106\u001b[0m, in \u001b[0;36m_compute_jacobian_wrt_params_with_sample_wise_trick\u001b[1;34m(model, inputs, labels, loss_fn, reduction_type, layer_modules)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     sample_grad_wrapper\u001b[38;5;241m.\u001b[39madd_hooks()\n\u001b[1;32m--> 106\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    108\u001b[0m         out\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    109\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure model output has at least one dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m loss_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\anast\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tda-for-fairness-5qunVEZW-py3.12\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\anast\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\tda-for-fairness-5qunVEZW-py3.12\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[1;31mTypeError\u001b[0m: WrappedModel.forward() takes 2 positional arguments but 5 were given"]}],"source":["embeddings = embedder.predict(eval_dataloader)"]},{"cell_type":"markdown","metadata":{"id":"CIzuQ5Hc0r4O"},"source":["### compute metadata for evaluation data ###\n","this will be the ingredient needed to display the clusters.  later on, it will also be used by the rule-based clusterer.  therefore, we also add it to the running `Data` instance for easy access."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oiRv_VFP0r4O"},"outputs":[],"source":["def _get_predictions_and_labels(_model, dataloader):\n","    dfs = []\n","    for batch in tqdm(dataloader):\n","        prediction_prob = (\n","            torch.nn.functional.softmax(_model(*batch[:-1]), dim=1)\n","            .detach()\n","            .to(device=\"cpu\")\n","        )\n","        prediction_label = torch.argmax(prediction_prob, dim=1).to(device=\"cpu\")\n","        label = batch[-1].to(\n","            device=\"cpu\"\n","        )  # assuming batch is a tensor.  if not, can check\n","        dfs.append(\n","            pd.DataFrame(\n","                {\n","                    \"prediction_label\": prediction_label,\n","                    \"label\": label,\n","                    \"prediction_prob\": list(prediction_prob.numpy()),\n","                }\n","            )\n","        )\n","    df = pd.concat(dfs, axis=0)\n","    df.index = list(range(len(df)))\n","    return df\n","\n","if True:\n","    metadata = _get_predictions_and_labels(model, eval_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wFfhBdPj0r4O"},"outputs":[],"source":["data.metadata = metadata\n","data.dataset = eval_dataset"]},{"cell_type":"markdown","metadata":{"id":"9_1H68m40r4O"},"source":["### define clusterer ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qpXjw3FI0r4O"},"outputs":[],"source":["if False:\n","    clusterer = SklearnClusterer(sklearn_clusterer=KMeans(n_clusters=25))\n","if True:\n","    clusterer = FAISSClusterer(k=25, spherical=True)"]},{"cell_type":"markdown","metadata":{"id":"6h10kZxp0r4O"},"source":["### do the clustering ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pF4FhakB0r4P"},"outputs":[],"source":["clusters = clusterer.fit_predict(data)"]},{"cell_type":"markdown","metadata":{"id":"7eNfWLPx0r4P"},"source":["### define ways to display clusters ###\n","these will all be functions whose input is a list of list of indices in the evaluation dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U4gu5kKK0r4P"},"outputs":[],"source":["from infembed.visualization._core.common import (\n","    DisplayMetadata,\n","    DisplayPIL,\n","    DisplayPredictionAndLabels,\n","    DisplaySingleExamples,\n","    PerClusterDisplayer,\n","    DisplayAccuracy,\n",")\n","\n","displayers = [\n","    PerClusterDisplayer(\n","        [\n","            DisplayAccuracy(prediction_col=\"prediction_label\", label_col=\"label\"),\n","            DisplayPredictionAndLabels(\n","                prediction_col=\"prediction_label_name\", label_col=\"label_name\"\n","            ),\n","            # DisplaySingleExamples(\n","            #     [\n","            #         DisplayMetadata([\"label_name\", \"prediction_label_name\"]),\n","            #         DisplayPIL(),\n","            #     ],\n","            #     limit=3,\n","            # ),\n","        ]\n","    )\n","]"]},{"cell_type":"markdown","metadata":{"id":"7Qd-6ece0r4P"},"source":["### display the clusters ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9q_bZ8SP0r4T"},"outputs":[],"source":["for displayer in displayers:\n","    displayer(clusters, data)"]},{"cell_type":"markdown","metadata":{"id":"icl8y_2s0r4U"},"source":["### define rule clusterer ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EwJky4160r4U"},"outputs":[],"source":["def _accuracy(data):\n","    return (data.metadata[\"prediction_label\"] == data.metadata[\"label\"]).mean()\n","\n","\n","def _size(data):\n","    return len(data)\n","\n","\n","rule_clusterer = RuleClusterer(\n","    # clusterer_getter=lambda n_clusters: SklearnClusterer(KMeans(n_clusters=n_clusters)),\n","    clusterer_getter=lambda n_clusters: FAISSClusterer(k=n_clusters, spherical=True),\n","    cluster_rule=lambda data: _accuracy(data) < 0.5 and _size(data) >= 10,\n","    stopping_rule=lambda data: _size(data) < 50,\n","    max_depth=7,\n","    branching_factor=3,\n",")"]},{"cell_type":"markdown","metadata":{"id":"eHTsG8YO0r4U"},"source":["### do the rule clustering ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NcJREBJ50r4U"},"outputs":[],"source":["rule_clusters = rule_clusterer.fit_predict(data)"]},{"cell_type":"markdown","metadata":{"id":"i_-4Wl9J0r4U"},"source":["### display the rule clusters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5mXCjl3-0r4V"},"outputs":[],"source":["for displayer in displayers:\n","    displayer(rule_clusters, data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_TAzW220r4V"},"outputs":[],"source":["assert False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BuqQA46I0r4V","outputId":"bde5772b-5206-466f-b6fd-476776c3cb93"},"outputs":[{"data":{"text/plain":["False"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["eval_dataset == eval_dataset_no_text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["071a2d2b54a548b498cf3a181d2d4620","b3ae8df19f674c72a3f632076fecc68c"]},"id":"ahpckOnw0r4V","outputId":"3d249385-6531-459e-b515-7b99f14d93c7"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"071a2d2b54a548b498cf3a181d2d4620","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3ae8df19f674c72a3f632076fecc68c","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 120000\n","    })\n","    test: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 7600\n","    })\n","})"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["dataset = dataset.map(lambda e: tokenizer(e['text']), batched=True)\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n54c1YKx0r4V","outputId":"041e7ff0-a0a9-4820-d7bf-c4b76ab04eef"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","    num_rows: 120000\n","})"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset = dataset['train']\n","train_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CM75KffO0r4W"},"outputs":[],"source":["train_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5eiABdPU0r4W"},"outputs":[],"source":["collate_fn = DataCollatorWithPadding(tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FIolEn3F0r4W","outputId":"f2c44a88-ea82-4412-c890-1b6a94053261"},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([[  101,  2813,  2358,  ...,     0,     0,     0],\n","        [  101, 18431,  2571,  ...,     0,     0,     0],\n","        [  101,  3514,  1998,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  9796, 11014,  ...,     0,     0,     0],\n","        [  101,  2900,  4517,  ...,     0,     0,     0],\n","        [  101,  8003, 12235,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","        2, 2, 2, 2, 2, 2, 2, 2])}"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["dataloader = torch.utils.data.DataLoader(train_dataset, collate_fn=collate_fn, batch_size=32)\n","batch = next(iter(dataloader))\n","batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVk5GZaF0r4X","outputId":"09b3bb49-f865-4e63-9c4b-8dc0a95f2a6f"},"outputs":[{"data":{"text/plain":["SequenceClassifierOutput(loss=tensor(0.3592, grad_fn=<NllLossBackward0>), logits=tensor([[-0.8737, -4.0619,  5.4155, -1.7417],\n","        [-1.1658, -4.0951,  5.4321, -1.4510],\n","        [-0.8620, -4.1424,  5.5314, -1.7337],\n","        [ 1.5970, -4.3902,  3.3570, -2.3064],\n","        [-1.0834, -3.9736,  5.6503, -1.7095],\n","        [-1.4935, -3.8177,  5.6872, -1.4512],\n","        [-1.3997, -3.7568,  5.7173, -1.5858],\n","        [-1.3014, -3.8335,  5.7024, -1.6216],\n","        [-1.3656, -3.8425,  5.6866, -1.5516],\n","        [-1.3806, -3.7999,  5.5882, -1.5492],\n","        [-1.3479, -3.8290,  5.7045, -1.5855],\n","        [-1.3728, -3.8659,  5.7086, -1.5305],\n","        [-1.3919, -3.7906,  5.7169, -1.5695],\n","        [-2.5567, -3.9876,  1.4896,  4.2655],\n","        [-1.2902, -3.8928,  5.6796, -1.5858],\n","        [-0.8614, -3.9113,  5.3037, -1.8322],\n","        [-1.8531, -3.6611,  4.8840, -0.7301],\n","        [-1.3917, -3.7502,  5.7070, -1.5974],\n","        [-1.2717, -3.8023,  5.6951, -1.6747],\n","        [ 0.2828, -4.1816,  4.7058, -2.3063],\n","        [-2.3727, -4.1623,  1.4551,  4.2885],\n","        [-0.7759, -4.1525,  5.4882, -1.7927],\n","        [ 1.2199, -4.2533,  3.9349, -2.4759],\n","        [-1.2171, -3.9493,  5.6878, -1.6129],\n","        [-0.6366, -4.0579,  5.2637, -1.9038],\n","        [-0.6983, -4.1170,  5.4075, -1.8611],\n","        [-1.4420, -3.9513,  5.1289, -1.1221],\n","        [-1.5401, -4.0135,  5.3416, -1.0794],\n","        [ 0.6353, -4.0691,  4.4273, -2.4835],\n","        [-0.5012, -4.1388,  5.3738, -1.9849],\n","        [ 4.3309, -2.7139, -1.0856, -1.4034],\n","        [-2.4877, -3.9174,  4.5552,  0.5155]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["model(**batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xOu9_EJY0r4X"},"outputs":[],"source":["data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0A9LF3W60r4X","outputId":"545276a5-f291-4a85-fc38-90f621873feb"},"outputs":[{"data":{"text/plain":["['SPECIAL_TOKENS_ATTRIBUTES',\n"," '__annotations__',\n"," '__call__',\n"," '__class__',\n"," '__delattr__',\n"," '__dict__',\n"," '__dir__',\n"," '__doc__',\n"," '__eq__',\n"," '__format__',\n"," '__ge__',\n"," '__getattribute__',\n"," '__gt__',\n"," '__hash__',\n"," '__init__',\n"," '__init_subclass__',\n"," '__le__',\n"," '__len__',\n"," '__lt__',\n"," '__module__',\n"," '__ne__',\n"," '__new__',\n"," '__reduce__',\n"," '__reduce_ex__',\n"," '__repr__',\n"," '__setattr__',\n"," '__sizeof__',\n"," '__str__',\n"," '__subclasshook__',\n"," '__weakref__',\n"," '_add_tokens',\n"," '_additional_special_tokens',\n"," '_auto_class',\n"," '_batch_encode_plus',\n"," '_bos_token',\n"," '_call_one',\n"," '_cls_token',\n"," '_convert_encoding',\n"," '_convert_id_to_token',\n"," '_convert_token_to_id_with_added_voc',\n"," '_create_repo',\n"," '_decode',\n"," '_decode_use_source_tokenizer',\n"," '_encode_plus',\n"," '_eos_token',\n"," '_eventual_warn_about_too_long_sequence',\n"," '_eventually_correct_t5_max_length',\n"," '_from_pretrained',\n"," '_get_files_timestamps',\n"," '_get_padding_truncation_strategies',\n"," '_in_target_context_manager',\n"," '_mask_token',\n"," '_pad',\n"," '_pad_token',\n"," '_pad_token_type_id',\n"," '_processor_class',\n"," '_save_pretrained',\n"," '_sep_token',\n"," '_set_processor_class',\n"," '_switch_to_input_mode',\n"," '_switch_to_target_mode',\n"," '_tokenizer',\n"," '_unk_token',\n"," '_upload_modified_files',\n"," 'add_special_tokens',\n"," 'add_tokens',\n"," 'additional_special_tokens',\n"," 'additional_special_tokens_ids',\n"," 'all_special_ids',\n"," 'all_special_tokens',\n"," 'all_special_tokens_extended',\n"," 'as_target_tokenizer',\n"," 'backend_tokenizer',\n"," 'batch_decode',\n"," 'batch_encode_plus',\n"," 'bos_token',\n"," 'bos_token_id',\n"," 'build_inputs_with_special_tokens',\n"," 'can_save_slow_tokenizer',\n"," 'clean_up_tokenization',\n"," 'clean_up_tokenization_spaces',\n"," 'cls_token',\n"," 'cls_token_id',\n"," 'convert_ids_to_tokens',\n"," 'convert_tokens_to_ids',\n"," 'convert_tokens_to_string',\n"," 'create_token_type_ids_from_sequences',\n"," 'decode',\n"," 'decoder',\n"," 'deprecation_warnings',\n"," 'do_lower_case',\n"," 'encode',\n"," 'encode_plus',\n"," 'eos_token',\n"," 'eos_token_id',\n"," 'from_pretrained',\n"," 'get_added_vocab',\n"," 'get_special_tokens_mask',\n"," 'get_vocab',\n"," 'init_inputs',\n"," 'init_kwargs',\n"," 'is_fast',\n"," 'mask_token',\n"," 'mask_token_id',\n"," 'max_len_sentences_pair',\n"," 'max_len_single_sentence',\n"," 'max_model_input_sizes',\n"," 'model_input_names',\n"," 'model_max_length',\n"," 'name_or_path',\n"," 'num_special_tokens_to_add',\n"," 'pad',\n"," 'pad_token',\n"," 'pad_token_id',\n"," 'pad_token_type_id',\n"," 'padding_side',\n"," 'prepare_for_model',\n"," 'prepare_seq2seq_batch',\n"," 'pretrained_init_configuration',\n"," 'pretrained_vocab_files_map',\n"," 'push_to_hub',\n"," 'register_for_auto_class',\n"," 'sanitize_special_tokens',\n"," 'save_pretrained',\n"," 'save_vocabulary',\n"," 'sep_token',\n"," 'sep_token_id',\n"," 'set_truncation_and_padding',\n"," 'slow_tokenizer_class',\n"," 'special_tokens_map',\n"," 'special_tokens_map_extended',\n"," 'split_special_tokens',\n"," 'tokenize',\n"," 'train_new_from_iterator',\n"," 'truncate_sequences',\n"," 'truncation_side',\n"," 'unk_token',\n"," 'unk_token_id',\n"," 'verbose',\n"," 'vocab',\n"," 'vocab_files_names',\n"," 'vocab_size']"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["dir(tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H9DfMK_R0r4X","outputId":"9cdfb997-9fae-4412-c413-da58aac470ec"},"outputs":[{"data":{"text/plain":["[101,\n"," 2813,\n"," 2358,\n"," 1012,\n"," 6468,\n"," 15020,\n"," 2067,\n"," 2046,\n"," 1996,\n"," 2304,\n"," 1006,\n"," 26665,\n"," 1007,\n"," 26665,\n"," 1011,\n"," 2460,\n"," 1011,\n"," 19041,\n"," 1010,\n"," 2813,\n"," 2395,\n"," 1005,\n"," 1055,\n"," 1040,\n"," 11101,\n"," 2989,\n"," 1032,\n"," 2316,\n"," 1997,\n"," 11087,\n"," 1011,\n"," 22330,\n"," 8713,\n"," 2015,\n"," 1010,\n"," 2024,\n"," 3773,\n"," 2665,\n"," 2153,\n"," 1012,\n"," 102,\n"," 18431,\n"," 2571,\n"," 3504,\n"," 2646,\n"," 3293,\n"," 13395,\n"," 1006,\n"," 26665,\n"," 1007,\n"," 26665,\n"," 1011,\n"," 2797,\n"," 5211,\n"," 3813,\n"," 18431,\n"," 2571,\n"," 2177,\n"," 1010,\n"," 1032,\n"," 2029,\n"," 2038,\n"," 1037,\n"," 5891,\n"," 2005,\n"," 2437,\n"," 2092,\n"," 1011,\n"," 22313,\n"," 1998,\n"," 5681,\n"," 1032,\n"," 6801,\n"," 3248,\n"," 1999,\n"," 1996,\n"," 3639,\n"," 3068,\n"," 1010,\n"," 2038,\n"," 5168,\n"," 2872,\n"," 1032,\n"," 2049,\n"," 29475,\n"," 2006,\n"," 2178,\n"," 2112,\n"," 1997,\n"," 1996,\n"," 3006,\n"," 1012,\n"," 102]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.encode([dataset['train'][0]['text'], dataset['train'][1]['text']])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v5XTiwwl0r4Y"},"outputs":[],"source":["tokenized = tokenizer([dataset['train'][0]['text'], dataset['train'][1]['text']])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C3Cz4ihC0r4Y","outputId":"8fe3977f-a6c2-4aa4-b029-2a12ca320e64"},"outputs":[{"ename":"ValueError","evalue":"You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['text', 'label']","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_collator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/transformers/data/data_collator.py:249\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m--> 249\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m    257\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3018\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3016\u001b[0m \u001b[38;5;66;03m# The model's main input name, usually `input_ids`, has be passed for padding\u001b[39;00m\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m encoded_inputs:\n\u001b[0;32m-> 3018\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3019\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should supply an encoding or a list of encodings to this method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat includes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but you provided \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(encoded_inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3021\u001b[0m     )\n\u001b[1;32m   3023\u001b[0m required_input \u001b[38;5;241m=\u001b[39m encoded_inputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m required_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(required_input, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(required_input) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n","\u001b[0;31mValueError\u001b[0m: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['text', 'label']"]},{"name":"stdout","output_type":"stream","text":["> \u001b[0;32m/home/ubuntu/miniconda3/envs/test2/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m(3018)\u001b[0;36mpad\u001b[0;34m()\u001b[0m\n","\u001b[0;32m   3016 \u001b[0;31m        \u001b[0;31m# The model's main input name, usually `input_ids`, has be passed for padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m   3017 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m-> 3018 \u001b[0;31m            raise ValueError(\n","\u001b[0m\u001b[0;32m   3019 \u001b[0;31m                \u001b[0;34m\"You should supply an encoding or a list of encodings to this method \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m   3020 \u001b[0;31m                \u001b[0;34mf\"that includes {self.model_input_names[0]}, but you provided {list(encoded_inputs.keys())}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\n"]}],"source":["data_collator([dataset['train'][0], dataset['train'][1]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TkYfaZQm0r4Y"},"outputs":[],"source":["d=dataset.map(lambda examples: tokenizer(examples['text']), batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3ZyCiwH0r4Y","outputId":"fe585ba5-c7b0-4ac9-8aaf-65cf20a90c8d"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 120000\n","    })\n","    test: Dataset({\n","        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 7600\n","    })\n","})"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["d"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pINb9NRB0r4Z","outputId":"a8c48312-9d3d-4a47-f00a-bea3ccab8d28"},"outputs":[{"ename":"ValueError","evalue":"Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`text` in this case) have excessive nesting (inputs type `list` where type `int` is expected).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:736\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 736\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:708\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(value))\n\u001b[0;32m--> 708\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDataCollatorWithPadding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/transformers/data/data_collator.py:249\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m--> 249\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m    257\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3099\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3096\u001b[0m             batch_outputs[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   3097\u001b[0m         batch_outputs[key]\u001b[38;5;241m.\u001b[39mappend(value)\n\u001b[0;32m-> 3099\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:211\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    207\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:752\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    748\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    749\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    750\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    751\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 752\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    753\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    754\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    755\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features (`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    756\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    757\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`text` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."]},{"name":"stdout","output_type":"stream","text":["> \u001b[0;32m/home/ubuntu/miniconda3/envs/test2/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m(752)\u001b[0;36mconvert_to_tensors\u001b[0;34m()\u001b[0m\n","\u001b[0;32m    750 \u001b[0;31m                        \u001b[0;34m\"Please see if a fast version of this tokenizer is available to have this feature available.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    751 \u001b[0;31m                    ) from e\n","\u001b[0m\u001b[0;32m--> 752 \u001b[0;31m                raise ValueError(\n","\u001b[0m\u001b[0;32m    753 \u001b[0;31m                    \u001b[0;34m\"Unable to create tensor, you should probably activate truncation and/or padding with\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    754 \u001b[0;31m                    \u001b[0;34m\" 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\n"]}],"source":["from torch.utils.data import DataLoader\n","next(iter(DataLoader(d['train'], batch_size=3, collate_fn=DataCollatorWithPadding(tokenizer))))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["8d24835ee0ba4650a2309de0bab12fce"]},"id":"RrpeOL880r4Z","outputId":"f7b80ade-ba2f-4d78-efd4-9375910a7f8a"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d24835ee0ba4650a2309de0bab12fce","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"ArrowInvalid","evalue":"Column 2 named g expected length 1000 but got length 3","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m d\u001b[38;5;241m=\u001b[39m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/datasets/dataset_dict.py:868\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[1;32m    867\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m--> 868\u001b[0m     {\n\u001b[1;32m    869\u001b[0m         k: dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m    870\u001b[0m             function\u001b[38;5;241m=\u001b[39mfunction,\n\u001b[1;32m    871\u001b[0m             with_indices\u001b[38;5;241m=\u001b[39mwith_indices,\n\u001b[1;32m    872\u001b[0m             with_rank\u001b[38;5;241m=\u001b[39mwith_rank,\n\u001b[1;32m    873\u001b[0m             input_columns\u001b[38;5;241m=\u001b[39minput_columns,\n\u001b[1;32m    874\u001b[0m             batched\u001b[38;5;241m=\u001b[39mbatched,\n\u001b[1;32m    875\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    876\u001b[0m             drop_last_batch\u001b[38;5;241m=\u001b[39mdrop_last_batch,\n\u001b[1;32m    877\u001b[0m             remove_columns\u001b[38;5;241m=\u001b[39mremove_columns,\n\u001b[1;32m    878\u001b[0m             keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory,\n\u001b[1;32m    879\u001b[0m             load_from_cache_file\u001b[38;5;241m=\u001b[39mload_from_cache_file,\n\u001b[1;32m    880\u001b[0m             cache_file_name\u001b[38;5;241m=\u001b[39mcache_file_names[k],\n\u001b[1;32m    881\u001b[0m             writer_batch_size\u001b[38;5;241m=\u001b[39mwriter_batch_size,\n\u001b[1;32m    882\u001b[0m             features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[1;32m    883\u001b[0m             disable_nullable\u001b[38;5;241m=\u001b[39mdisable_nullable,\n\u001b[1;32m    884\u001b[0m             fn_kwargs\u001b[38;5;241m=\u001b[39mfn_kwargs,\n\u001b[1;32m    885\u001b[0m             num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[1;32m    886\u001b[0m             desc\u001b[38;5;241m=\u001b[39mdesc,\n\u001b[1;32m    887\u001b[0m         )\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    889\u001b[0m     }\n\u001b[1;32m    890\u001b[0m )\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/datasets/dataset_dict.py:869\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[1;32m    867\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m    868\u001b[0m     {\n\u001b[0;32m--> 869\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    889\u001b[0m     }\n\u001b[1;32m    890\u001b[0m )\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/datasets/arrow_dataset.py:592\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 592\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/datasets/arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    555\u001b[0m }\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/datasets/arrow_dataset.py:3093\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3087\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3088\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3089\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3090\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3091\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3092\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3093\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3094\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3095\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/datasets/arrow_dataset.py:3489\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3487\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwrite_table(pa\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_pandas(batch))\n\u001b[1;32m   3488\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3489\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3490\u001b[0m num_examples_progress_update \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_examples_in_batch\n\u001b[1;32m   3491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m _time \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mPBAR_REFRESH_TIME_INTERVAL:\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/datasets/arrow_writer.py:560\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[0;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[1;32m    558\u001b[0m         inferred_features[col] \u001b[38;5;241m=\u001b[39m typed_sequence\u001b[38;5;241m.\u001b[39mget_inferred_type()\n\u001b[1;32m    559\u001b[0m schema \u001b[38;5;241m=\u001b[39m inferred_features\u001b[38;5;241m.\u001b[39marrow_schema \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema\n\u001b[0;32m--> 560\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_table(pa_table, writer_batch_size)\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/pyarrow/table.pxi:3798\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_arrays\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/pyarrow/table.pxi:2962\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.validate\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n","\u001b[0;31mArrowInvalid\u001b[0m: Column 2 named g expected length 1000 but got length 3"]},{"name":"stdout","output_type":"stream","text":["> \u001b[0;32m/home/ubuntu/Documents/infembed/infembed/examples/agnews/pyarrow/error.pxi\u001b[0m(100)\u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n","\n"]}],"source":["d=dataset.map(lambda examples: {'g': torch.Tensor([1,2,3])}, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W8AcXIwU0r4Z","outputId":"adaf9b3c-ecc6-4890-e7ac-36581e3c82f7"},"outputs":[{"ename":"ValueError","evalue":"text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2602\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2600\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2601\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2602\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2604\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n","File \u001b[0;32m~/miniconda3/envs/test2/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2660\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2660\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2661\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2662\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2663\u001b[0m     )\n\u001b[1;32m   2665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2667\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2668\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2669\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."]},{"name":"stdout","output_type":"stream","text":["> \u001b[0;32m/home/ubuntu/miniconda3/envs/test2/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m(2660)\u001b[0;36m_call_one\u001b[0;34m()\u001b[0m\n","\u001b[0;32m   2658 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m   2659 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_valid_text_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m-> 2660 \u001b[0;31m            raise ValueError(\n","\u001b[0m\u001b[0;32m   2661 \u001b[0;31m                \u001b[0;34m\"text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m   2662 \u001b[0;31m                \u001b[0;34m\"or `List[List[str]]` (batch of pretokenized examples).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\n"]}],"source":["tokenizer(dataset['train'][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TeWljmyw0r4Z","outputId":"d28162b9-dabc-4123-abf6-55f3b0938929"},"outputs":[{"data":{"text/plain":["{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",\n"," 'label': 2}"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["dataset['train'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KNWB5fP90r4a"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"065f9297c0d6439297bd26066fb1c876":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44cee22ed207492fb0d85cbcc3074c17","max":120000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b59e5cfbaf947eca750692fcf109b77","value":120000}},"067d99e674664b43aeece0060bb7dbaf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"089fbfa0c55d47e3ba7d8e5b16753176":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3dbcdfd4ef894935a1bbb92e3574e777","IPY_MODEL_1f36b20660234d00ae03463d663c601a","IPY_MODEL_4041ebd2d65a4168819b41834cec6964"],"layout":"IPY_MODEL_443e1b7211414a6da74753968bb7e82a"}},"098d6f07eb1d405eacda4cf2878b69c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29f9b3d23a5543d6ba063273a22ac4b3","placeholder":"​","style":"IPY_MODEL_ff1305043867418182a21b5459164622","value":"Downloading readme: 100%"}},"0c112badf1474188aa33ef43e7dee7e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c4aeac53f024b20bbc579ad6f36b0bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c5c9baa63324176b41df1a183a4c92f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cfba98e4e0244e7b516b773bd8f4e0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2ba4a756ebe48d99a6bd7d7b12dcbb0","placeholder":"​","style":"IPY_MODEL_e8c956c5c373475e8961834bf6846f12","value":"Downloading data: 100%"}},"0d2aa05e70a444488bde7c5146ea4be5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d469e2fcad743b581c4721449876c85":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e0298ff53c749ed97b6840f5b66b058":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_098d6f07eb1d405eacda4cf2878b69c1","IPY_MODEL_1f35cb36518f40d8946d649c88481d9c","IPY_MODEL_80276e6d08df4610922d0c8c70871c36"],"layout":"IPY_MODEL_8675a42e1829469f83c3868f8babfaf9"}},"0f896251d121484ba71a8e53fcd12300":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"116e61e7c48f407db8e9b79bf69a279e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11db5672df0c4110904a5af30949633b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29e30877f88a4edf91cd30ab94416d50","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_41fa277be78f4c6b8d0ccb1d60e5426e","value":231508}},"162ae4630cfa464db7c337bceeb45ee0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc4d13aeaa844bb181b2127f82ab2b16","placeholder":"​","style":"IPY_MODEL_5910a7e2827540129ff32a6d25d963c0","value":" 18.6M/18.6M [00:00&lt;00:00, 39.1MB/s]"}},"1a18788ecde140eb9e3370064faf92e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24b7063463cb4d15b102ca558b82f206","placeholder":"​","style":"IPY_MODEL_2c9ad1a526144820b99a573bb19b3efb","value":"Generating train split: 100%"}},"1f35cb36518f40d8946d649c88481d9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7c31c6cdf06449d9626dc05bb41ed08","max":8070,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5f2c4cca4c64f7d957a2999918faabe","value":8070}},"1f36b20660234d00ae03463d663c601a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d9f2324a1aa4f4ebe21e5b108206c70","max":321,"min":0,"orientation":"horizontal","style":"IPY_MODEL_23b09e46890e421196833addbcc2974c","value":321}},"1fa0fffe4e034eb5bd95a07f156ee253":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23b09e46890e421196833addbcc2974c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"241d52645a454c618a5a11182a89d754":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24b7063463cb4d15b102ca558b82f206":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29e30877f88a4edf91cd30ab94416d50":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29f9b3d23a5543d6ba063273a22ac4b3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2aa13b24964d4dfcbced015c1ce66962":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b853b166dc740a5be17c4cd7ff76c31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c9ad1a526144820b99a573bb19b3efb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ce4febc017c4d748703362b2c933f44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e6550884f404009811ba344440f5555":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f2e0567a0fd44f3944f21ffad84438c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9db9e04191fa46c586e6939a063b08d9","max":438030207,"min":0,"orientation":"horizontal","style":"IPY_MODEL_851905f19b6a4ae28e9e66c10e79af60","value":438030207}},"2f8d3cbf852c44249e537c915c7007d4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"366fe9502717401e9c07fea7fbea13a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a4588e26add47abb8dce591e05dc3c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf9b4c4adf2746b181a19414202cff05","IPY_MODEL_11db5672df0c4110904a5af30949633b","IPY_MODEL_559d33f3ffcf4192af9952a2c333277c"],"layout":"IPY_MODEL_ae41758bbf6b430eb5ecab1b96ea0ff8"}},"3a48b97187a74d859df4e03e5fe06f0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_808c87432b6446f7814389c7090bc71f","placeholder":"​","style":"IPY_MODEL_8b054d47d5ea498d856914509c8a405b","value":" 919/919 [00:00&lt;00:00, 41.8kB/s]"}},"3dbcdfd4ef894935a1bbb92e3574e777":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5b688e1f10c4eb29baac238ee215411","placeholder":"​","style":"IPY_MODEL_46b3a835bd5a4f469d6a6411d8c915ba","value":"tokenizer_config.json: 100%"}},"4041ebd2d65a4168819b41834cec6964":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcdd806adcaf477ba2138863a4628781","placeholder":"​","style":"IPY_MODEL_b20ac25335b94138a5b0b72b7a38e4f2","value":" 321/321 [00:00&lt;00:00, 18.2kB/s]"}},"41fa277be78f4c6b8d0ccb1d60e5426e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4268b99847a9411fb008e400960b18ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_889dd502e5284867ba9ad4485e37287b","max":1234829,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8384d218cb97468bacef63329ebde93f","value":1234829}},"443e1b7211414a6da74753968bb7e82a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44cee22ed207492fb0d85cbcc3074c17":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46b3a835bd5a4f469d6a6411d8c915ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47c6d774fafc4022a35f6ecf071dbefb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"488fb950b922473fb15816979b3cd33e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48c0a6e7af6444109de88fb82e846512":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_366fe9502717401e9c07fea7fbea13a1","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e7eef311a744414bdd17905c080ea3f","value":112}},"49aaf641478b48bfafcbeaa7dcee1a65":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c5b8700fb604fd2a8dc333b21d0a554":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c5d37de37b14cdfb12423f128f0798d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dc94c0a8e364e78a6855f5fd65495fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b61aab8be2194d50b00f1724cb65b30f","placeholder":"​","style":"IPY_MODEL_793f698c279447b7a9036a70b1d7c3a1","value":" 112/112 [00:00&lt;00:00, 6.35kB/s]"}},"50ae707dce6645258a9f8b54e04df0fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dfd626ab9c24852a27805be5c4613ba","max":7600,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9538c6b032b8415295a9f57b89cdfa06","value":7600}},"54847501dc6c4b0784a050b90a793ce6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"559d33f3ffcf4192af9952a2c333277c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1ed0b4d7e9149dfb0b863358f01ee6a","placeholder":"​","style":"IPY_MODEL_0f896251d121484ba71a8e53fcd12300","value":" 232k/232k [00:00&lt;00:00, 2.15MB/s]"}},"56780cf4e94942a38562f4ead034bd6e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5910a7e2827540129ff32a6d25d963c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a1bca8446a149dc98a210584e8b951e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f219e3fbc34f41bfbddfec77939cd957","max":238,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d2aa05e70a444488bde7c5146ea4be5","value":0}},"5edf026c132644639f0c28037061f2a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b667b51c25e43dba344c409467e8f9d","IPY_MODEL_5a1bca8446a149dc98a210584e8b951e","IPY_MODEL_b5dc214cedf846e583b47fe751943d50"],"layout":"IPY_MODEL_0c4aeac53f024b20bbc579ad6f36b0bf"}},"5f624935fc234d10ade3b6b25c5ea9c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2aa13b24964d4dfcbced015c1ce66962","placeholder":"​","style":"IPY_MODEL_067d99e674664b43aeece0060bb7dbaf","value":" 5000/5000 [00:01&lt;00:00, 3877.40 examples/s]"}},"6569a6359bde412987b2d664d1842c5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"662fecb18fe1402d810e05f4aec796ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"665c944864c24810ac5213d7a2975c1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edabf30aebf746e8b6cfff20b211ae05","placeholder":"​","style":"IPY_MODEL_1fa0fffe4e034eb5bd95a07f156ee253","value":"tokenizer.json: 100%"}},"66c5d9e8a9794e258c82d427c518ae3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f12b6059f9643c7afeb913cedf4cd11","placeholder":"​","style":"IPY_MODEL_786284c1ccbf4dc3b9f4d92292360217","value":" 466k/466k [00:00&lt;00:00, 9.60MB/s]"}},"6887b63140644b5a998f689ff38cb151":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b59e5cfbaf947eca750692fcf109b77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6d3a15340cf841d7bbd0a32ae3b369e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b304365f3d6c4b5ca214b47544a581e4","placeholder":"​","style":"IPY_MODEL_6569a6359bde412987b2d664d1842c5c","value":" 7600/7600 [00:00&lt;00:00, 127091.51 examples/s]"}},"6dfd626ab9c24852a27805be5c4613ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f21c77df7d1413d9abd3bf1aa3131cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"718d0a315973410e9d351c72d7499aca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"71a3822a801446ec9a7551abbfb1c828":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec45db1861b141f186b9111135b4903b","placeholder":"​","style":"IPY_MODEL_7596deea0cbf4665b02dd1853e4ea068","value":"Map: 100%"}},"72ab1cc6356d4c70a4965c46ce104d95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79e9b444543a47a9a211eb963cc89049","max":919,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be399f9ab8434291a029ba2ef7f9ecab","value":919}},"72c0c5dc253d4f659a6047eeb2df8c1f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74b4ac85e4e049b8b3effb9508c02801":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7596deea0cbf4665b02dd1853e4ea068":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78151583c96e456081483aaa629690c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_71a3822a801446ec9a7551abbfb1c828","IPY_MODEL_f0944b532a674b9b99773393d1be3584","IPY_MODEL_5f624935fc234d10ade3b6b25c5ea9c9"],"layout":"IPY_MODEL_72c0c5dc253d4f659a6047eeb2df8c1f"}},"786284c1ccbf4dc3b9f4d92292360217":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"793f698c279447b7a9036a70b1d7c3a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79e9b444543a47a9a211eb963cc89049":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b667b51c25e43dba344c409467e8f9d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_488fb950b922473fb15816979b3cd33e","placeholder":"​","style":"IPY_MODEL_e82fa53de8f34cf79c1abf862452d503","value":"Using ArnoldiEmbedder to compute embeddings. Processing batch:   0%"}},"7e7eef311a744414bdd17905c080ea3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f12b6059f9643c7afeb913cedf4cd11":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f26955c9fe544a89506f9ecb8cfbcc1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b779a1716f6a490ca4c3639ac3bacaf1","IPY_MODEL_50ae707dce6645258a9f8b54e04df0fe","IPY_MODEL_6d3a15340cf841d7bbd0a32ae3b369e0"],"layout":"IPY_MODEL_de2c234c5f7b4928a4d2934e7cc74ebc"}},"80276e6d08df4610922d0c8c70871c36":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3fb84ea2714478bbcb04ac7d8eeb54d","placeholder":"​","style":"IPY_MODEL_e63177bb4a7642278eb7a8674e0c959a","value":" 8.07k/8.07k [00:00&lt;00:00, 219kB/s]"}},"808c87432b6446f7814389c7090bc71f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8384d218cb97468bacef63329ebde93f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"851905f19b6a4ae28e9e66c10e79af60":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8675a42e1829469f83c3868f8babfaf9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"889dd502e5284867ba9ad4485e37287b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b054d47d5ea498d856914509c8a405b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c7f421795df4b469277a74bc4a4fcec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f355b48d81c244aa93d6b75bfd65e210","IPY_MODEL_72ab1cc6356d4c70a4965c46ce104d95","IPY_MODEL_3a48b97187a74d859df4e03e5fe06f0b"],"layout":"IPY_MODEL_0c5c9baa63324176b41df1a183a4c92f"}},"8feccdd3bc064cd38800c8edef512164":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"931f7157bdab4855b28e1a4ee5306f7f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9538c6b032b8415295a9f57b89cdfa06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"95a90fe26d414859ac6335c5ec45273b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7d0cbaec09847519068faa6bf69e7a1","IPY_MODEL_eb3f8da3908b4d67bdf6e559eb03fc50","IPY_MODEL_d8a091dff8ad48fc969a4202fe4c2e54"],"layout":"IPY_MODEL_d5505849562145e1ba52653b53faa758"}},"9602c555f9f7459391dde07172953630":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8286f59810f4c248dac84c5b4c8294b","placeholder":"​","style":"IPY_MODEL_241d52645a454c618a5a11182a89d754","value":"Downloading data: 100%"}},"989876d8befc47a3b876ab8d51474024":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b33e12dfc47467cb0d77aa7c6f93d2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d9f2324a1aa4f4ebe21e5b108206c70":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9db9e04191fa46c586e6939a063b08d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eff554f16bf44b0bb253d9453af6e9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0cfba98e4e0244e7b516b773bd8f4e0b","IPY_MODEL_4268b99847a9411fb008e400960b18ae","IPY_MODEL_ce7cd3ff30a1408da253735dcf4e6dba"],"layout":"IPY_MODEL_ceacfc34216e46a7bf8b93933e4c1c05"}},"a1ed0b4d7e9149dfb0b863358f01ee6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7d0cbaec09847519068faa6bf69e7a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54847501dc6c4b0784a050b90a793ce6","placeholder":"​","style":"IPY_MODEL_2e6550884f404009811ba344440f5555","value":"Map: 100%"}},"a8286f59810f4c248dac84c5b4c8294b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a93de48eb10b4e7abe651dad0633d526":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc8aef60efbf4d4aa38557987239c754","IPY_MODEL_2f2e0567a0fd44f3944f21ffad84438c","IPY_MODEL_fad42df95e0845f2bfdb0f938ca61774"],"layout":"IPY_MODEL_d47e01c6bc204995b1745a1af187a91d"}},"aa74c8de1ae0467fa41670138eb37b7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae41758bbf6b430eb5ecab1b96ea0ff8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b20ac25335b94138a5b0b72b7a38e4f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b304365f3d6c4b5ca214b47544a581e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3fb84ea2714478bbcb04ac7d8eeb54d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b449fb965413441c9a933cd3692c3680":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5b688e1f10c4eb29baac238ee215411":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5dc214cedf846e583b47fe751943d50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_931f7157bdab4855b28e1a4ee5306f7f","placeholder":"​","style":"IPY_MODEL_e32393b2df724b2caf40e5acbe4e3683","value":" 0/238 [00:00&lt;?, ?it/s]"}},"b5f2c4cca4c64f7d957a2999918faabe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b61aab8be2194d50b00f1724cb65b30f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b779a1716f6a490ca4c3639ac3bacaf1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_116e61e7c48f407db8e9b79bf69a279e","placeholder":"​","style":"IPY_MODEL_d612370820e34272ad46b4579d0b0aa8","value":"Generating test split: 100%"}},"b9a424a5c7c8452096cd123e9530330d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49aaf641478b48bfafcbeaa7dcee1a65","placeholder":"​","style":"IPY_MODEL_47c6d774fafc4022a35f6ecf071dbefb","value":" 120000/120000 [00:00&lt;00:00, 191774.63 examples/s]"}},"bb4c12b63127423ba5bb8ef3deb43aed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_665c944864c24810ac5213d7a2975c1b","IPY_MODEL_ed16d8969502476f9b854c8bdac69757","IPY_MODEL_66c5d9e8a9794e258c82d427c518ae3e"],"layout":"IPY_MODEL_74b4ac85e4e049b8b3effb9508c02801"}},"bcc10b05097748d196204c8503835386":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcd6cc6e2d75462c87228178ad0ef329":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdb5a2b28c1842db8a8245bf5d958820":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be399f9ab8434291a029ba2ef7f9ecab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c47b3d8660874d0099d20cf9b4b394bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7c31c6cdf06449d9626dc05bb41ed08":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce7cd3ff30a1408da253735dcf4e6dba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdb5a2b28c1842db8a8245bf5d958820","placeholder":"​","style":"IPY_MODEL_8feccdd3bc064cd38800c8edef512164","value":" 1.23M/1.23M [00:00&lt;00:00, 5.80MB/s]"}},"ceacfc34216e46a7bf8b93933e4c1c05":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf9b4c4adf2746b181a19414202cff05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_989876d8befc47a3b876ab8d51474024","placeholder":"​","style":"IPY_MODEL_aa74c8de1ae0467fa41670138eb37b7e","value":"vocab.txt: 100%"}},"d2ba4a756ebe48d99a6bd7d7b12dcbb0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d47e01c6bc204995b1745a1af187a91d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5505849562145e1ba52653b53faa758":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d612370820e34272ad46b4579d0b0aa8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8a091dff8ad48fc969a4202fe4c2e54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcc10b05097748d196204c8503835386","placeholder":"​","style":"IPY_MODEL_fede1881044744b0a7ff246cd78430b1","value":" 7600/7600 [00:04&lt;00:00, 1819.69 examples/s]"}},"d900c5a3747d4f1693822a680e150305":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e3ec58ad43f24cc88a628a79a2ec0700","IPY_MODEL_48c0a6e7af6444109de88fb82e846512","IPY_MODEL_4dc94c0a8e364e78a6855f5fd65495fd"],"layout":"IPY_MODEL_4c5d37de37b14cdfb12423f128f0798d"}},"dc6b31db6f514f18a3b785c268cb8fbf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc8aef60efbf4d4aa38557987239c754":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b33e12dfc47467cb0d77aa7c6f93d2e","placeholder":"​","style":"IPY_MODEL_6887b63140644b5a998f689ff38cb151","value":"pytorch_model.bin: 100%"}},"dd24e1a1fd424bd0b1e47a3598dcf5e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a18788ecde140eb9e3370064faf92e2","IPY_MODEL_065f9297c0d6439297bd26066fb1c876","IPY_MODEL_b9a424a5c7c8452096cd123e9530330d"],"layout":"IPY_MODEL_0d469e2fcad743b581c4721449876c85"}},"de2c234c5f7b4928a4d2934e7cc74ebc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0c9d203273b46509dc18c1178af3969":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e32393b2df724b2caf40e5acbe4e3683":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3ec58ad43f24cc88a628a79a2ec0700":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f8d3cbf852c44249e537c915c7007d4","placeholder":"​","style":"IPY_MODEL_6f21c77df7d1413d9abd3bf1aa3131cd","value":"special_tokens_map.json: 100%"}},"e51b1f493cee48598f278f75e3b1791c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e63177bb4a7642278eb7a8674e0c959a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e82fa53de8f34cf79c1abf862452d503":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8c956c5c373475e8961834bf6846f12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb3f8da3908b4d67bdf6e559eb03fc50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ce4febc017c4d748703362b2c933f44","max":7600,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c47b3d8660874d0099d20cf9b4b394bf","value":7600}},"ec45db1861b141f186b9111135b4903b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed16d8969502476f9b854c8bdac69757":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0c9d203273b46509dc18c1178af3969","max":466248,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc6b31db6f514f18a3b785c268cb8fbf","value":466248}},"edabf30aebf746e8b6cfff20b211ae05":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef5aeb5848a14807a59bb15589bfd253":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcd6cc6e2d75462c87228178ad0ef329","max":18585438,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b853b166dc740a5be17c4cd7ff76c31","value":18585438}},"f0944b532a674b9b99773393d1be3584":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c5b8700fb604fd2a8dc333b21d0a554","max":5000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_718d0a315973410e9d351c72d7499aca","value":5000}},"f219e3fbc34f41bfbddfec77939cd957":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f355b48d81c244aa93d6b75bfd65e210":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b449fb965413441c9a933cd3692c3680","placeholder":"​","style":"IPY_MODEL_662fecb18fe1402d810e05f4aec796ff","value":"config.json: 100%"}},"f6e58335649d4ae5b38de8dd9bad4da1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9602c555f9f7459391dde07172953630","IPY_MODEL_ef5aeb5848a14807a59bb15589bfd253","IPY_MODEL_162ae4630cfa464db7c337bceeb45ee0"],"layout":"IPY_MODEL_e51b1f493cee48598f278f75e3b1791c"}},"fad42df95e0845f2bfdb0f938ca61774":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56780cf4e94942a38562f4ead034bd6e","placeholder":"​","style":"IPY_MODEL_0c112badf1474188aa33ef43e7dee7e8","value":" 438M/438M [00:05&lt;00:00, 56.9MB/s]"}},"fc4d13aeaa844bb181b2127f82ab2b16":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcdd806adcaf477ba2138863a4628781":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fede1881044744b0a7ff246cd78430b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff1305043867418182a21b5459164622":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
